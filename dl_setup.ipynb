{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1478532c-329c-4894-afc0-802da75f8dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Project structure created: ['data', 'models', 'notebooks', 'src']\n",
      "âœ… Seeds fixed to: 42\n",
      "ğŸ“¦ Suggested packages: ['numpy', 'pandas', 'scikit-learn', 'tensorflow', 'nltk', 'spacy', 'sentence-transformers', 'shap', 'lime', 'matplotlib']\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 0 â€” Project Setup\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define project structure\n",
    "project_dirs = [\"data\", \"models\", \"notebooks\", \"src\"]\n",
    "\n",
    "for d in project_dirs:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Project structure created:\", project_dirs)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"âœ… Seeds fixed to:\", seed)\n",
    "\n",
    "# Verify packages (if running fresh environment)\n",
    "required_packages = [\n",
    "    \"numpy\", \"pandas\", \"scikit-learn\", \"tensorflow\", \n",
    "    \"nltk\", \"spacy\", \"sentence-transformers\", \"shap\", \"lime\", \"matplotlib\"\n",
    "]\n",
    "print(\"ğŸ“¦ Suggested packages:\", required_packages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9420ad4-b7b8-45f9-8fe0-d6046d233dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Domain requirement files saved.\n",
      "âœ… Generated 2000 synthetic resumes and saved to data/synthetic_resumes.json\n",
      "{\n",
      "  \"id\": \"candidate_0000\",\n",
      "  \"skills\": [\n",
      "    \"CI/CD\",\n",
      "    \"PyTorch\",\n",
      "    \"Azure\",\n",
      "    \"SQL\",\n",
      "    \"Terraform\",\n",
      "    \"React\"\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    \"Image Classification using CNN\",\n",
      "    \"ETL Pipeline with Spark\"\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"title\": \"Cloud Engineer\",\n",
      "      \"years\": 2\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Backend Developer\",\n",
      "      \"years\": 3\n",
      "    }\n",
      "  ],\n",
      "  \"test_score\": 54,\n",
      "  \"preferred_domain\": \"Cloud Engineering\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 1 â€” Generate / Collect Dataset\n",
    "# ================================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- 1.2 Domain Requirements ----------\n",
    "domain_requirements = {\n",
    "    \"Data Science\": {\n",
    "        \"domain\": \"Data Science\",\n",
    "        \"required_skills\": [\n",
    "            \"Python\", \"Pandas\", \"NumPy\", \"Scikit-learn\", \"PyTorch\", \"Docker\", \"Deep Learning\"\n",
    "        ]\n",
    "    },\n",
    "    \"Web Development\": {\n",
    "        \"domain\": \"Web Development\",\n",
    "        \"required_skills\": [\n",
    "            \"HTML\", \"CSS\", \"JavaScript\", \"React\", \"Node.js\", \"Express\", \"SQL\"\n",
    "        ]\n",
    "    },\n",
    "    \"Cloud Engineering\": {\n",
    "        \"domain\": \"Cloud Engineering\",\n",
    "        \"required_skills\": [\n",
    "            \"AWS\", \"Azure\", \"Docker\", \"Kubernetes\", \"Linux\", \"Terraform\", \"CI/CD\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save domain requirement files\n",
    "os.makedirs(\"data/domain_requirements\", exist_ok=True)\n",
    "for domain, req in domain_requirements.items():\n",
    "    with open(f\"data/domain_requirements/{domain.lower().replace(' ','_')}.json\", \"w\") as f:\n",
    "        json.dump(req, f, indent=4)\n",
    "\n",
    "print(\"âœ… Domain requirement files saved.\")\n",
    "\n",
    "\n",
    "# ---------- 1.3 Synthetic Resume Generator ----------\n",
    "skills_pool = list(set(sum([req[\"required_skills\"] for req in domain_requirements.values()], []))) + [\n",
    "    \"C++\", \"Java\", \"SQL\", \"Tableau\", \"Hadoop\", \"Spark\", \"Flask\"\n",
    "]\n",
    "\n",
    "job_titles = [\"Data Scientist\", \"Data Analyst\", \"ML Engineer\", \"Backend Developer\", \"Frontend Developer\", \"Cloud Engineer\"]\n",
    "\n",
    "projects_pool = [\n",
    "    \"Image Classification using CNN\", \"Web Scraping with Python\", \"Portfolio Website\",\n",
    "    \"Cloud Infrastructure Setup\", \"ETL Pipeline with Spark\", \"Dashboard with React\"\n",
    "]\n",
    "\n",
    "def generate_resume(idx, domains):\n",
    "    domain = np.random.choice(list(domains.keys()))\n",
    "    required = domains[domain][\"required_skills\"]\n",
    "\n",
    "    # Randomly sample skills\n",
    "    n_skills = np.random.randint(3, 10)\n",
    "    skills = list(np.random.choice(skills_pool, n_skills, replace=False))\n",
    "\n",
    "    # Projects\n",
    "    n_projects = np.random.randint(0, 4)\n",
    "    projects = list(np.random.choice(projects_pool, n_projects, replace=False))\n",
    "\n",
    "    # Work experience\n",
    "    n_exp = np.random.randint(1, 3)\n",
    "    work_experience = [\n",
    "        {\"title\": np.random.choice(job_titles), \"years\": np.random.randint(0, 6)}\n",
    "        for _ in range(n_exp)\n",
    "    ]\n",
    "\n",
    "    # Test score from clipped normal distribution (mean=65, std=20)\n",
    "    test_score = int(np.clip(np.random.normal(65, 20), 0, 100))\n",
    "\n",
    "    resume = {\n",
    "        \"id\": f\"candidate_{idx:04d}\",\n",
    "        \"skills\": skills,\n",
    "        \"projects\": projects,\n",
    "        \"work_experience\": work_experience,\n",
    "        \"test_score\": test_score,\n",
    "        \"preferred_domain\": domain\n",
    "    }\n",
    "    return resume\n",
    "\n",
    "\n",
    "# Generate N=2000 synthetic resumes\n",
    "N = 2000\n",
    "synthetic_resumes = [generate_resume(i, domain_requirements) for i in range(N)]\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"data/synthetic_resumes.json\", \"w\") as f:\n",
    "    json.dump(synthetic_resumes, f, indent=4)\n",
    "\n",
    "print(f\"âœ… Generated {N} synthetic resumes and saved to data/synthetic_resumes.json\")\n",
    "\n",
    "# Quick peek at one sample\n",
    "print(json.dumps(synthetic_resumes[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4cb07d-8805-4e60-ab79-25d6c9545eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rule-based labels assigned and saved to data/labeled_resumes.json\n",
      "\n",
      "Label Distribution:\n",
      " Partial Fit    1170\n",
      "Not Fit         827\n",
      "Fit               3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample Resume with Label:\n",
      " {\n",
      "  \"id\": \"candidate_0000\",\n",
      "  \"skills\": [\n",
      "    \"CI/CD\",\n",
      "    \"PyTorch\",\n",
      "    \"Azure\",\n",
      "    \"SQL\",\n",
      "    \"Terraform\",\n",
      "    \"React\"\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    \"Image Classification using CNN\",\n",
      "    \"ETL Pipeline with Spark\"\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"title\": \"Cloud Engineer\",\n",
      "      \"years\": 2\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Backend Developer\",\n",
      "      \"years\": 3\n",
      "    }\n",
      "  ],\n",
      "  \"test_score\": 54,\n",
      "  \"preferred_domain\": \"Cloud Engineering\",\n",
      "  \"matched_skills\": [\n",
      "    \"Azure\",\n",
      "    \"CI/CD\",\n",
      "    \"Terraform\"\n",
      "  ],\n",
      "  \"missing_skills\": [\n",
      "    \"Docker\",\n",
      "    \"Kubernetes\",\n",
      "    \"Linux\",\n",
      "    \"AWS\"\n",
      "  ],\n",
      "  \"skill_match_ratio\": 0.43,\n",
      "  \"test_score_norm\": 0.54,\n",
      "  \"project_count\": 2,\n",
      "  \"label\": \"Partial Fit\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 2 â€” Create Ground Truth Labels (Rule-based)\n",
    "# ================================\n",
    "\n",
    "# Load domain requirements\n",
    "domain_req_map = {}\n",
    "for domain, req in domain_requirements.items():\n",
    "    domain_req_map[domain] = set(req[\"required_skills\"])\n",
    "\n",
    "def assign_label(resume, domain_req_map):\n",
    "    domain = resume[\"preferred_domain\"]\n",
    "    required_skills = domain_req_map[domain]\n",
    "    candidate_skills = set(resume[\"skills\"])\n",
    "\n",
    "    # Matched & missing skills\n",
    "    matched_skills = candidate_skills.intersection(required_skills)\n",
    "    missing_skills = required_skills - candidate_skills\n",
    "\n",
    "    # Ratios & counts\n",
    "    skill_match_ratio = len(matched_skills) / len(required_skills) if required_skills else 0\n",
    "    test_score_norm = resume[\"test_score\"] / 100\n",
    "    project_count = len(resume[\"projects\"])\n",
    "\n",
    "    # Apply labeling rules\n",
    "    if (skill_match_ratio >= 0.70) and (test_score_norm >= 0.75) and (project_count >= 1):\n",
    "        label = \"Fit\"\n",
    "    elif (0.40 <= skill_match_ratio < 0.70) or (0.50 <= test_score_norm < 0.75):\n",
    "        label = \"Partial Fit\"\n",
    "    else:\n",
    "        label = \"Not Fit\"\n",
    "\n",
    "    # Add extra fields\n",
    "    resume[\"matched_skills\"] = list(matched_skills)\n",
    "    resume[\"missing_skills\"] = list(missing_skills)\n",
    "    resume[\"skill_match_ratio\"] = round(skill_match_ratio, 2)\n",
    "    resume[\"test_score_norm\"] = round(test_score_norm, 2)\n",
    "    resume[\"project_count\"] = project_count\n",
    "    resume[\"label\"] = label\n",
    "\n",
    "    return resume\n",
    "\n",
    "\n",
    "# Apply labeling to all resumes\n",
    "labeled_resumes = [assign_label(r, domain_req_map) for r in synthetic_resumes]\n",
    "\n",
    "# Save labeled dataset\n",
    "with open(\"data/labeled_resumes.json\", \"w\") as f:\n",
    "    json.dump(labeled_resumes, f, indent=4)\n",
    "\n",
    "print(\"âœ… Rule-based labels assigned and saved to data/labeled_resumes.json\")\n",
    "\n",
    "# Quick distribution check\n",
    "label_counts = pd.Series([r[\"label\"] for r in labeled_resumes]).value_counts()\n",
    "print(\"\\nLabel Distribution:\\n\", label_counts)\n",
    "\n",
    "# Peek at one labeled resume\n",
    "print(\"\\nSample Resume with Label:\\n\", json.dumps(labeled_resumes[0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2e680d-54f0-450e-a7d8-4a94b3d2732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned dataset: 2000 resumes (from 2000)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step A â€” Data Cleaning after Generation\n",
    "# ================================\n",
    "\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Canonical vocab (from domain requirements)\n",
    "canonical_skills = sorted(set(sum([req[\"required_skills\"] for req in domain_requirements.values()], [])))\n",
    "\n",
    "# Stopwords for projects\n",
    "stopwords = {\"and\", \"the\", \"project\", \"using\"}\n",
    "\n",
    "# Canonical job titles\n",
    "canonical_titles = [\"data scientist\", \"data analyst\", \"machine learning engineer\", \"intern\", \n",
    "                    \"backend developer\", \"frontend developer\", \"cloud engineer\"]\n",
    "\n",
    "def normalize_skill(skill, canonical_vocab):\n",
    "    s = skill.strip().lower()\n",
    "    # Try exact canonical match\n",
    "    if s in [c.lower() for c in canonical_vocab]:\n",
    "        return s\n",
    "    # Try fuzzy matching (closest skill)\n",
    "    match = get_close_matches(s, [c.lower() for c in canonical_vocab], n=1, cutoff=0.8)\n",
    "    if match:\n",
    "        return match[0]\n",
    "    return s   # keep as-is if no good match\n",
    "\n",
    "def clean_projects(projects):\n",
    "    cleaned = []\n",
    "    for p in projects:\n",
    "        p = p.lower()\n",
    "        p = re.sub(r\"[^a-z0-9 ]\", \" \", p)  # remove punctuation\n",
    "        tokens = [t for t in p.split() if t not in stopwords]\n",
    "        if len(tokens) >= 2:\n",
    "            cleaned.append(\" \".join(tokens))\n",
    "    return list(set(cleaned))  # deduplicate\n",
    "\n",
    "def normalize_title(title):\n",
    "    t = title.lower().strip()\n",
    "    match = get_close_matches(t, canonical_titles, n=1, cutoff=0.7)\n",
    "    return match[0] if match else t\n",
    "\n",
    "def clean_years(years):\n",
    "    try:\n",
    "        y = float(re.sub(\"[^0-9.]\", \"\", str(years)))\n",
    "        return max(y, 0)  # clamp negatives\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def clean_resume(resume):\n",
    "    # Skills\n",
    "    resume[\"skills\"] = list({normalize_skill(s, canonical_skills) for s in resume[\"skills\"]})\n",
    "    \n",
    "    # Projects\n",
    "    resume[\"projects\"] = clean_projects(resume[\"projects\"])\n",
    "    \n",
    "    # Work experience\n",
    "    cleaned_exp = []\n",
    "    for exp in resume[\"work_experience\"]:\n",
    "        cleaned_exp.append({\n",
    "            \"title\": normalize_title(exp[\"title\"]),\n",
    "            \"years\": clean_years(exp[\"years\"])\n",
    "        })\n",
    "    resume[\"work_experience\"] = cleaned_exp\n",
    "    \n",
    "    # Test score\n",
    "    score = resume.get(\"test_score\", 0)\n",
    "    score = max(0, min(score, 100))  # clamp\n",
    "    resume[\"test_score\"] = int(score)\n",
    "    resume[\"test_score_norm\"] = round(score/100, 2)\n",
    "    \n",
    "    return resume\n",
    "\n",
    "# Apply cleaning\n",
    "cleaned_resumes = [clean_resume(r) for r in labeled_resumes]\n",
    "\n",
    "# Remove corrupted/duplicates\n",
    "seen = set()\n",
    "final_resumes = []\n",
    "for r in cleaned_resumes:\n",
    "    key = (tuple(sorted(r[\"skills\"])), tuple(r[\"projects\"]), r[\"test_score\"], r[\"preferred_domain\"])\n",
    "    if not r[\"skills\"] and not r[\"projects\"] and r[\"test_score\"] == 0:\n",
    "        continue  # drop corrupted\n",
    "    if r[\"preferred_domain\"] == \"\":\n",
    "        continue\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    final_resumes.append(r)\n",
    "\n",
    "print(f\"âœ… Cleaned dataset: {len(final_resumes)} resumes (from {len(labeled_resumes)})\")\n",
    "\n",
    "# Save cleaned data\n",
    "with open(\"data/cleaned_resumes.json\", \"w\") as f:\n",
    "    json.dump(final_resumes, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b01943-4b1c-460b-888f-c7547fb17392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing: Counter({'Partial Fit': 1170, 'Not Fit': 827, 'Fit': 3})\n",
      "After balancing: Counter({'Partial Fit': 1170, 'Not Fit': 1170, 'Fit': 1170})\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step B â€” Label Balancing\n",
    "# ================================\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "labels = [r[\"label\"] for r in final_resumes]\n",
    "counts = Counter(labels)\n",
    "print(\"Before balancing:\", counts)\n",
    "\n",
    "max_count = max(counts.values())\n",
    "balanced_resumes = []\n",
    "\n",
    "for label, count in counts.items():\n",
    "    group = [r for r in final_resumes if r[\"label\"] == label]\n",
    "    if count < max_count:\n",
    "        # Oversample minority\n",
    "        extra = random.choices(group, k=max_count - count)\n",
    "        balanced_resumes.extend(group + extra)\n",
    "    else:\n",
    "        balanced_resumes.extend(group)\n",
    "\n",
    "balanced_counts = Counter([r[\"label\"] for r in balanced_resumes])\n",
    "print(\"After balancing:\", balanced_counts)\n",
    "\n",
    "# Save balanced dataset\n",
    "with open(\"data/balanced_resumes.json\", \"w\") as f:\n",
    "    json.dump(balanced_resumes, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a1eaa5-aea5-499b-a1a6-00f62437a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Built skill vocabulary of size 46\n",
      "\n",
      "=== Sample Resume Features ===\n",
      "Skill vector length: 46\n",
      "Matched: []\n",
      "Missing: ['Linux', 'Kubernetes', 'Azure', 'Terraform', 'AWS', 'CI/CD', 'Docker']\n",
      "Skill match ratio: 0.0\n",
      "Project count: 2 â†’ scaled: 0.43\n",
      "Years experience: 5.0 â†’ scaled: 0.5\n",
      "Normalized test score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 3 â€” Preprocessing & Helper Functions\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 3.1 Build skill vocabulary\n",
    "def build_skill_vocab(resumes, domain_requirements):\n",
    "    all_skills = set()\n",
    "    for r in resumes:\n",
    "        all_skills.update(r[\"skills\"])\n",
    "    for domain, req in domain_requirements.items():\n",
    "        all_skills.update(req[\"required_skills\"])\n",
    "    skill_vocab = sorted(all_skills)\n",
    "    return skill_vocab\n",
    "\n",
    "skill_vocab = build_skill_vocab(final_resumes, domain_requirements)\n",
    "skill_index = {s: i for i, s in enumerate(skill_vocab)}\n",
    "skill_vocab_size = len(skill_vocab)\n",
    "\n",
    "print(f\"âœ… Built skill vocabulary of size {skill_vocab_size}\")\n",
    "\n",
    "\n",
    "# 3.2 Skill encoding function\n",
    "def encode_skills(candidate_skills, skill_index):\n",
    "    vector = np.zeros(len(skill_index), dtype=int)\n",
    "    for s in candidate_skills:\n",
    "        if s in skill_index:\n",
    "            vector[skill_index[s]] = 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "# 3.3 Matched & missing skills\n",
    "def matched_missing_skills(candidate_skills, domain_required_skills):\n",
    "    candidate_set = set(candidate_skills)\n",
    "    required_set = set(domain_required_skills)\n",
    "    matched = list(candidate_set.intersection(required_set))\n",
    "    missing = list(required_set - candidate_set)\n",
    "    ratio = len(matched) / len(required_set) if required_set else 0\n",
    "    return matched, missing, round(ratio, 2)\n",
    "\n",
    "\n",
    "# 3.4 Project & experience features\n",
    "def extract_project_experience_features(resume):\n",
    "    project_count = len(resume.get(\"projects\", []))\n",
    "    years_experience = sum(item.get(\"years\", 0) for item in resume.get(\"work_experience\", []))\n",
    "    return project_count, years_experience\n",
    "\n",
    "\n",
    "# 3.5 Test score normalization\n",
    "def normalize_test_score(score):\n",
    "    return round(score / 100, 2)\n",
    "\n",
    "\n",
    "# 3.6 Numeric feature scaling (fit & transform on dataset)\n",
    "def fit_numeric_scalers(resumes):\n",
    "    project_counts = []\n",
    "    years_exp = []\n",
    "    \n",
    "    for r in resumes:\n",
    "        p, y = extract_project_experience_features(r)\n",
    "        project_counts.append(p)\n",
    "        years_exp.append(y)\n",
    "    \n",
    "    project_scaler = StandardScaler()\n",
    "    years_scaler = StandardScaler()\n",
    "    \n",
    "    project_scaler.fit(np.array(project_counts).reshape(-1, 1))\n",
    "    years_scaler.fit(np.array(years_exp).reshape(-1, 1))\n",
    "    \n",
    "    return project_scaler, years_scaler\n",
    "\n",
    "def transform_numeric_features(resume, project_scaler, years_scaler):\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    project_scaled = project_scaler.transform([[project_count]])[0][0]\n",
    "    years_scaled = years_scaler.transform([[years_exp]])[0][0]\n",
    "    return project_scaled, years_scaled\n",
    "\n",
    "\n",
    "# ================================\n",
    "# âœ… Test the helper functions\n",
    "# ================================\n",
    "# Fit scalers on dataset\n",
    "project_scaler, years_scaler = fit_numeric_scalers(final_resumes)\n",
    "\n",
    "sample = final_resumes[0]\n",
    "\n",
    "# Encode skills\n",
    "skill_vector = encode_skills(sample[\"skills\"], skill_index)\n",
    "\n",
    "# Matched & missing\n",
    "domain = sample[\"preferred_domain\"]\n",
    "matched, missing, ratio = matched_missing_skills(sample[\"skills\"], domain_requirements[domain][\"required_skills\"])\n",
    "\n",
    "# Numeric features\n",
    "p_count, y_exp = extract_project_experience_features(sample)\n",
    "p_scaled, y_scaled = transform_numeric_features(sample, project_scaler, years_scaler)\n",
    "\n",
    "# Test score norm\n",
    "score_norm = normalize_test_score(sample[\"test_score\"])\n",
    "\n",
    "print(\"\\n=== Sample Resume Features ===\")\n",
    "print(\"Skill vector length:\", len(skill_vector))\n",
    "print(\"Matched:\", matched)\n",
    "print(\"Missing:\", missing)\n",
    "print(\"Skill match ratio:\", ratio)\n",
    "print(\"Project count:\", p_count, \"â†’ scaled:\", round(p_scaled, 2))\n",
    "print(\"Years experience:\", y_exp, \"â†’ scaled:\", round(y_scaled, 2))\n",
    "print(\"Normalized test score:\", score_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2069441-7e17-4eb7-9e6e-59f5498a8026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pavan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "âœ… SBERT model loaded for text embeddings\n",
      "\n",
      "=== Final Vector Details ===\n",
      "Skill vector size: 46\n",
      "Skill branch size (with ratio): 47\n",
      "Numeric branch size: 4\n",
      "Text branch size: 384\n",
      "Final vector size: 435\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 4 â€” Final Feature Vector\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    use_embeddings = True\n",
    "    print(\"âœ… SBERT model loaded for text embeddings\")\n",
    "except ImportError:\n",
    "    sbert_model = None\n",
    "    use_embeddings = False\n",
    "    print(\"âš ï¸ SentenceTransformer not installed â€” skipping text embeddings\")\n",
    "\n",
    "\n",
    "def build_final_vector(resume, domain_requirements, skill_index, \n",
    "                       project_scaler, years_scaler, use_embeddings=False):\n",
    "    \"\"\"\n",
    "    Construct final feature vector for a single resume.\n",
    "    \"\"\"\n",
    "    # 1. Skills branch\n",
    "    skill_vector = encode_skills(resume[\"skills\"], skill_index)  # binary\n",
    "    domain = resume[\"preferred_domain\"]\n",
    "    matched, missing, ratio = matched_missing_skills(resume[\"skills\"], domain_requirements[domain][\"required_skills\"])\n",
    "    \n",
    "    # Add skill_match_ratio as scalar numeric feature\n",
    "    skill_features = np.append(skill_vector, ratio)\n",
    "\n",
    "    # 2. Numeric branch\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    project_scaled, years_scaled = transform_numeric_features(resume, project_scaler, years_scaler)\n",
    "    test_score_norm = normalize_test_score(resume[\"test_score\"])\n",
    "    numeric_vector = np.array([test_score_norm, project_scaled, years_scaled, ratio])\n",
    "\n",
    "    # 3. Optional text branch (project titles & job titles)\n",
    "    if use_embeddings and sbert_model:\n",
    "        project_titles = resume.get(\"projects\", [])\n",
    "        exp_titles = [exp[\"title\"] for exp in resume.get(\"work_experience\", [])]\n",
    "        text_items = project_titles + exp_titles\n",
    "        if text_items:\n",
    "            project_embedding = np.mean(sbert_model.encode(text_items), axis=0)\n",
    "        else:\n",
    "            project_embedding = np.zeros(384)  # MiniLM embedding size\n",
    "    else:\n",
    "        project_embedding = np.array([])  # skip if not using embeddings\n",
    "\n",
    "    # 4. Concatenate all branches\n",
    "    final_vector = np.concatenate([skill_features, numeric_vector, project_embedding])\n",
    "    return final_vector\n",
    "\n",
    "\n",
    "# ================================\n",
    "# âœ… Test on a sample resume\n",
    "# ================================\n",
    "\n",
    "sample = final_resumes[0]\n",
    "final_vec = build_final_vector(sample, domain_requirements, skill_index, \n",
    "                               project_scaler, years_scaler, use_embeddings)\n",
    "\n",
    "print(\"\\n=== Final Vector Details ===\")\n",
    "print(\"Skill vector size:\", len(skill_vocab))\n",
    "print(\"Skill branch size (with ratio):\", len(skill_vocab) + 1)\n",
    "print(\"Numeric branch size:\", 4)\n",
    "if use_embeddings:\n",
    "    print(\"Text branch size:\", len(final_vec) - (len(skill_vocab) + 1 + 4))\n",
    "else:\n",
    "    print(\"Text branch skipped\")\n",
    "print(\"Final vector size:\", len(final_vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e1b6d67-119b-4585-93a8-c26517dc07a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ skill_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> â”‚ skill_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ numeric_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> â”‚ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             â”‚\n",
       "â”‚                               â”‚                           â”‚                 â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,560</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ skill_input (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               â”‚          \u001b[38;5;34m12,288\u001b[0m â”‚ skill_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ numeric_input (\u001b[38;5;33mInputLayer\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                â”‚             \u001b[38;5;34m160\u001b[0m â”‚ numeric_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               â”‚          \u001b[38;5;34m32,896\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                â”‚             \u001b[38;5;34m528\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             â”‚\n",
       "â”‚                               â”‚                           â”‚                 â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               â”‚          \u001b[38;5;34m18,560\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 â”‚             \u001b[38;5;34m195\u001b[0m â”‚ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,883</span> (284.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m72,883\u001b[0m (284.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,883</span> (284.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m72,883\u001b[0m (284.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 5 â€” Model Architecture\n",
    "# ================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_resume_classifier(skill_vocab_size, numeric_size=4, text_embedding_size=None, learning_rate=1e-3):\n",
    "    \"\"\"\n",
    "    Build a hybrid Keras model for resume classification.\n",
    "    \n",
    "    Args:\n",
    "        skill_vocab_size: int â†’ number of skills in vocabulary\n",
    "        numeric_size: int â†’ number of numeric features (default 4)\n",
    "        text_embedding_size: int or None â†’ dimension of text embedding if used\n",
    "        learning_rate: float â†’ learning rate for optimizer\n",
    "    \"\"\"\n",
    "    # 5.1 Inputs\n",
    "    skill_input = Input(shape=(skill_vocab_size,), name=\"skill_input\")\n",
    "    numeric_input = Input(shape=(numeric_size,), name=\"numeric_input\")\n",
    "    inputs = [skill_input, numeric_input]\n",
    "    \n",
    "    # Optional text input\n",
    "    if text_embedding_size:\n",
    "        project_input = Input(shape=(text_embedding_size,), name=\"project_input\")\n",
    "        inputs.append(project_input)\n",
    "    else:\n",
    "        project_input = None\n",
    "    \n",
    "    # 5.2 Skills branch\n",
    "    x1 = Dense(256, activation=\"relu\")(skill_input)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(128, activation=\"relu\")(x1)\n",
    "    \n",
    "    # 5.3 Numeric branch\n",
    "    x2 = Dense(32, activation=\"relu\")(numeric_input)\n",
    "    x2 = Dense(16, activation=\"relu\")(x2)\n",
    "    \n",
    "    # 5.4 Project/text branch\n",
    "    if project_input is not None:\n",
    "        x3 = Dense(128, activation=\"relu\")(project_input)\n",
    "        x3 = Dense(64, activation=\"relu\")(x3)\n",
    "        concat = concatenate([x1, x2, x3])\n",
    "    else:\n",
    "        concat = concatenate([x1, x2])\n",
    "    \n",
    "    # 5.5 Concatenate â†’ hidden layers\n",
    "    h = Dense(128, activation=\"relu\")(concat)\n",
    "    h = Dropout(0.3)(h)\n",
    "    h = Dense(64, activation=\"relu\")(h)\n",
    "    \n",
    "    # 5.6 Output (3 classes: Fit, Partial Fit, Not Fit)\n",
    "    out = Dense(3, activation=\"softmax\", name=\"output\")(h)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    \n",
    "    # 5.7 Compile\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ================================\n",
    "# âœ… Build model (without text embeddings for now)\n",
    "# ================================\n",
    "V = skill_vocab_size + 1   # skills + ratio\n",
    "numeric_size = 4\n",
    "text_embedding_size = None   # or 384 if using SBERT embeddings\n",
    "\n",
    "model = build_resume_classifier(V, numeric_size, text_embedding_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82188bd5-2d99-4a95-be2c-6d81d606e76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2469, Val size: 529, Test size: 530\n",
      "Class weights: {0: 1.0, 1: 1.0, 2: 1.0}\n",
      "Epoch 1/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.6541 - loss: 0.5846 - val_accuracy: 0.7032 - val_loss: 0.4592\n",
      "Epoch 2/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6825 - loss: 0.4640 - val_accuracy: 0.7013 - val_loss: 0.4540\n",
      "Epoch 3/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7278 - loss: 0.4523 - val_accuracy: 0.7183 - val_loss: 0.4498\n",
      "Epoch 4/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7363 - loss: 0.4411 - val_accuracy: 0.7410 - val_loss: 0.4456\n",
      "Epoch 5/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7456 - loss: 0.4355 - val_accuracy: 0.7335 - val_loss: 0.4467\n",
      "Epoch 6/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7618 - loss: 0.4239 - val_accuracy: 0.7467 - val_loss: 0.4431\n",
      "Epoch 7/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7736 - loss: 0.4098 - val_accuracy: 0.7240 - val_loss: 0.4495\n",
      "Epoch 8/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8007 - loss: 0.3882 - val_accuracy: 0.7467 - val_loss: 0.4452\n",
      "Epoch 9/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8068 - loss: 0.3687 - val_accuracy: 0.7353 - val_loss: 0.4706\n",
      "Epoch 10/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8339 - loss: 0.3449 - val_accuracy: 0.7543 - val_loss: 0.4642\n",
      "Epoch 11/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8473 - loss: 0.3152 - val_accuracy: 0.7713 - val_loss: 0.4514\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 6 â€” Training Procedure\n",
    "# ================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare dataset (features + labels)\n",
    "# -------------------------------\n",
    "def prepare_dataset(resumes, domain_requirements, skill_index, project_scaler, years_scaler, use_embeddings=False):\n",
    "    X_skills, X_numeric, X_text, y = [], [], [], []\n",
    "    \n",
    "    for r in resumes:\n",
    "        # Skill branch (skills + ratio already included in build_final_vector)\n",
    "        skill_vector = encode_skills(r[\"skills\"], skill_index)\n",
    "        domain = r[\"preferred_domain\"]\n",
    "        _, _, ratio = matched_missing_skills(r[\"skills\"], domain_requirements[domain][\"required_skills\"])\n",
    "        skill_features = np.append(skill_vector, ratio)\n",
    "        \n",
    "        # Numeric branch\n",
    "        project_scaled, years_scaled = transform_numeric_features(r, project_scaler, years_scaler)\n",
    "        test_score_norm = normalize_test_score(r[\"test_score\"])\n",
    "        numeric_vector = np.array([test_score_norm, project_scaled, years_scaled, ratio])\n",
    "        \n",
    "        # Optional text branch\n",
    "        if use_embeddings and sbert_model:\n",
    "            project_titles = r.get(\"projects\", [])\n",
    "            exp_titles = [exp[\"title\"] for exp in r.get(\"work_experience\", [])]\n",
    "            text_items = project_titles + exp_titles\n",
    "            if text_items:\n",
    "                project_embedding = np.mean(sbert_model.encode(text_items), axis=0)\n",
    "            else:\n",
    "                project_embedding = np.zeros(384)\n",
    "        else:\n",
    "            project_embedding = None\n",
    "        \n",
    "        X_skills.append(skill_features)\n",
    "        X_numeric.append(numeric_vector)\n",
    "        if use_embeddings:\n",
    "            X_text.append(project_embedding)\n",
    "        y.append(r[\"label\"])\n",
    "    \n",
    "    X_skills = np.array(X_skills)\n",
    "    X_numeric = np.array(X_numeric)\n",
    "    if use_embeddings:\n",
    "        X_text = np.array(X_text)\n",
    "    else:\n",
    "        X_text = None\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    y_onehot = to_categorical(y_encoded, num_classes=3)\n",
    "    \n",
    "    return X_skills, X_numeric, X_text, y_onehot, label_encoder\n",
    "\n",
    "\n",
    "# Load balanced dataset\n",
    "with open(\"data/balanced_resumes.json\", \"r\") as f:\n",
    "    balanced_resumes = json.load(f)\n",
    "\n",
    "X_skills, X_numeric, X_text, y, label_encoder = prepare_dataset(\n",
    "    balanced_resumes, domain_requirements, skill_index, project_scaler, years_scaler, use_embeddings=False\n",
    ")\n",
    "\n",
    "# Train/val/test split (70/15/15 stratified)\n",
    "X_train_s, X_temp_s, X_train_n, X_temp_n, y_train, y_temp = train_test_split(\n",
    "    X_skills, X_numeric, y, test_size=0.30, stratify=y, random_state=42\n",
    ")\n",
    "X_val_s, X_test_s, X_val_n, X_test_n, y_val, y_test = train_test_split(\n",
    "    X_temp_s, X_temp_n, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train_s)}, Val size: {len(X_val_s)}, Test size: {len(X_test_s)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Class weights\n",
    "# -------------------------------\n",
    "classes = np.argmax(y, axis=1)\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(classes), y=classes)\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# -------------------------------\n",
    "# Callbacks\n",
    "# -------------------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"models/best_model.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# Train model\n",
    "# -------------------------------\n",
    "history = model.fit(\n",
    "    {\"skill_input\": X_train_s, \"numeric_input\": X_train_n},\n",
    "    y_train,\n",
    "    validation_data=({\"skill_input\": X_val_s, \"numeric_input\": X_val_n}, y_val),\n",
    "    class_weight=class_weight_dict,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97cdced2-050f-41ad-acec-6d93ff1297dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "Accuracy: 0.715\n",
      "Precision: 0.715\n",
      "Recall: 0.715\n",
      "F1 Score: 0.714\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Fit       0.99      1.00      1.00       177\n",
      "     Not Fit       0.58      0.51      0.54       177\n",
      " Partial Fit       0.57      0.64      0.60       176\n",
      "\n",
      "    accuracy                           0.72       530\n",
      "   macro avg       0.71      0.71      0.71       530\n",
      "weighted avg       0.72      0.72      0.71       530\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 7 â€” Metrics & Evaluation\n",
    "# ================================\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_probs = model.predict({\"skill_input\": X_test_s, \"numeric_input\": X_test_n})\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Accuracy, Precision, Recall, F1\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\n=== Evaluation Metrics ===\")\n",
    "print(\"Accuracy:\", round(acc, 3))\n",
    "print(\"Precision:\", round(precision, 3))\n",
    "print(\"Recall:\", round(recall, 3))\n",
    "print(\"F1 Score:\", round(f1, 3))\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Calibration: predicted probability histogram\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(np.max(y_pred_probs, axis=1), bins=20, edgecolor=\"k\")\n",
    "plt.title(\"Prediction Confidence Distribution\")\n",
    "plt.xlabel(\"Max softmax probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0de51e4-265c-427c-a28e-1951f504033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Rule-based explanation (short) ---\n",
      "\n",
      "Predicted label: Partial Fit (model confidence: 0.56) Raw test score: 54 / 100 (normalized: 0.54) Skill match: 0 / 7 â†’\n",
      "ratio 0.00 Projects: 2; Years experience (sum): 5.0 Top missing required skills: Linux, Kubernetes, Azure\n",
      "Recommendations: Add containerization (Docker) example or CI/CD step.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 8 â€” Interpretability & Explanation\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "import textwrap\n",
    "\n",
    "# Helper: build flat vector used by model (same logic as Step 4)\n",
    "def build_flat_vector_for_model(resume, skill_index, project_scaler, years_scaler, use_embeddings=False):\n",
    "    # skill binary\n",
    "    skill_vec = encode_skills(resume[\"skills\"], skill_index)\n",
    "    # matched ratio\n",
    "    _, _, ratio = matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])\n",
    "    # append ratio to skill vector (as used earlier)\n",
    "    skill_features = np.append(skill_vec, ratio).astype(float)\n",
    "    # numeric vector (test_score_norm, project_scaled, years_scaled, ratio)\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    project_scaled, years_scaled = transform_numeric_features(resume, project_scaler, years_scaler)\n",
    "    test_score_norm = normalize_test_score(resume[\"test_score\"])\n",
    "    numeric_vector = np.array([test_score_norm, project_scaled, years_scaled, ratio], dtype=float)\n",
    "    # final concatenation (no text embeddings here; if you used embeddings in training, extend accordingly)\n",
    "    final = np.concatenate([skill_features, numeric_vector])\n",
    "    return final, skill_features, numeric_vector, ratio\n",
    "\n",
    "# Prediction wrapper: accepts single flat vector and returns softmax probs\n",
    "def predict_from_flat_vector(flat_vec):\n",
    "    # split back into inputs expected by the Keras model\n",
    "    V_plus_ratio = len(skill_vocab) + 1  # same as during training: skill_vocab + ratio\n",
    "    skill_input = flat_vec[:V_plus_ratio].reshape(1, -1)\n",
    "    numeric_input = flat_vec[V_plus_ratio:V_plus_ratio + 4].reshape(1, -1)\n",
    "    preds = model.predict({\"skill_input\": skill_input, \"numeric_input\": numeric_input}, verbose=0)\n",
    "    return preds.flatten()\n",
    "\n",
    "# Rule-based explanation template generator\n",
    "def rule_based_explanation(resume, prob, label):\n",
    "    matched, missing, ratio = matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    raw_score = resume.get(\"test_score\", None)\n",
    "    score_norm = normalize_test_score(raw_score) if raw_score is not None else None\n",
    "    top_missing = missing[:3] if missing else []\n",
    "    \n",
    "    lines = []\n",
    "    lines.append(f\"Predicted label: {label} (model confidence: {prob:.2f})\")\n",
    "    lines.append(f\"Raw test score: {raw_score} / 100 (normalized: {score_norm:.2f})\")\n",
    "    lines.append(f\"Skill match: {len(matched)} / {len(domain_requirements[resume['preferred_domain']]['required_skills'])} â†’ ratio {ratio:.2f}\")\n",
    "    lines.append(f\"Projects: {project_count}; Years experience (sum): {years_exp}\")\n",
    "    if top_missing:\n",
    "        lines.append(\"Top missing required skills: \" + \", \".join(top_missing))\n",
    "    else:\n",
    "        lines.append(\"No missing required skills (meets all listed domain requirements).\")\n",
    "    \n",
    "    # Add quick recommendation\n",
    "    recs = []\n",
    "    if label != \"Fit\":\n",
    "        if \"PyTorch\" in top_missing or \"Deep Learning\" in top_missing:\n",
    "            recs.append(\"Add a Deep Learning project (PyTorch/TensorFlow).\")\n",
    "        if \"Docker\" in top_missing or \"Kubernetes\" in top_missing:\n",
    "            recs.append(\"Add containerization (Docker) example or CI/CD step.\")\n",
    "        if len(resume.get(\"projects\", [])) == 0:\n",
    "            recs.append(\"Add at least one hands-on project demonstrating key skills.\")\n",
    "    if not recs:\n",
    "        lines.append(\"Recommendation: Keep profile and add more high-impact projects to increase confidence.\")\n",
    "    else:\n",
    "        lines.append(\"Recommendations: \" + \" \".join(recs))\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Optional: SHAP attribution (if shap installed). We use KernelExplainer on a small background subset.\n",
    "def shap_explain(resume_flat, background_flat_array, feature_names=None, nsamples=100):\n",
    "    try:\n",
    "        import shap\n",
    "    except Exception as e:\n",
    "        print(\"SHAP not available:\", e)\n",
    "        return None\n",
    "    \n",
    "    # function that maps a 2D array of flat vectors -> model probabilities for each class (returns shape n x 3)\n",
    "    def f(X):\n",
    "        preds = []\n",
    "        for row in X:\n",
    "            preds.append(predict_from_flat_vector(row))\n",
    "        return np.vstack(preds)\n",
    "    \n",
    "    explainer = shap.KernelExplainer(f, background_flat_array, link=\"identity\")\n",
    "    # explain original instance\n",
    "    shap_values = explainer.shap_values(resume_flat, nsamples=nsamples)\n",
    "    # shap_values is list length n_classes; each is array (1, n_features)\n",
    "    return shap_values\n",
    "\n",
    "# Sensitivity test: perturb test_score by +/- 10% and observe label/confidence changes\n",
    "def sensitivity_test(resume, skill_index, project_scaler, years_scaler):\n",
    "    base_flat, skill_features, numeric_vector, ratio = build_flat_vector_for_model(resume, skill_index, project_scaler, years_scaler)\n",
    "    base_probs = predict_from_flat_vector(base_flat)\n",
    "    base_label = label_encoder.inverse_transform([np.argmax(base_probs)])[0]\n",
    "    # prepare perturbed resume copies\n",
    "    perturbed_results = {}\n",
    "    for pct in [-0.1, 0.1]:\n",
    "        new_resume = dict(resume)  # shallow copy\n",
    "        new_score = int(np.clip(resume.get(\"test_score\",0) * (1 + pct), 0, 100))\n",
    "        new_resume[\"test_score\"] = new_score\n",
    "        pert_flat, _, _, _ = build_flat_vector_for_model(new_resume, skill_index, project_scaler, years_scaler)\n",
    "        probs = predict_from_flat_vector(pert_flat)\n",
    "        label = label_encoder.inverse_transform([np.argmax(probs)])[0]\n",
    "        perturbed_results[f\"{int(pct*100)}%\"] = {\"test_score\": new_score, \"label\": label, \"confidence\": float(np.max(probs))}\n",
    "    return {\n",
    "        \"base\": {\"test_score\": int(resume.get(\"test_score\",0)), \"label\": base_label, \"confidence\": float(np.max(base_probs))},\n",
    "        \"perturbations\": perturbed_results\n",
    "    }\n",
    "\n",
    "# Main explanation function combining everything\n",
    "def explain_resume(resume, skill_index, project_scaler, years_scaler, background_resumes_for_shap=None, shap_nsamples=100, use_shap=False):\n",
    "    # Build flat\n",
    "    flat, _, _, _ = build_flat_vector_for_model(resume, skill_index, project_scaler, years_scaler)\n",
    "    probs = predict_from_flat_vector(flat)\n",
    "    pred_idx = int(np.argmax(probs))\n",
    "    pred_label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "    pred_conf = float(np.max(probs))\n",
    "    \n",
    "    # Rule-based explanation\n",
    "    rule_text = rule_based_explanation(resume, pred_conf, pred_label)\n",
    "    \n",
    "    # SHAP (optional)\n",
    "    shap_result = None\n",
    "    if use_shap:\n",
    "        if background_resumes_for_shap is None:\n",
    "            print(\"No background provided for SHAP; skipping SHAP.\")\n",
    "        else:\n",
    "            # build background flat array (take up to 50)\n",
    "            bg_flats = []\n",
    "            for r in background_resumes_for_shap[:50]:\n",
    "                bf, _, _, _ = build_flat_vector_for_model(r, skill_index, project_scaler, years_scaler)\n",
    "                bg_flats.append(bf)\n",
    "            bg_arr = np.vstack(bg_flats)\n",
    "            sv = shap_explain(flat, bg_arr, nsamples=shap_nsamples)\n",
    "            if sv is not None:\n",
    "                # format top positive/negative contributors for predicted class\n",
    "                class_shap = sv[pred_idx].flatten()  # shape (n_features,)\n",
    "                # pair feature names: first V features are skill names + 'skill_match_ratio', then numeric features\n",
    "                feat_names = skill_vocab + [\"skill_match_ratio\", \"test_score_norm\", \"project_count_scaled\", \"years_experience_scaled\", \"skill_match_ratio_dup\"]\n",
    "                # Note: because we concatenated skill_features then numeric_vector, ensure names align; adjust if necessary.\n",
    "                # We'll create simple top-K summary:\n",
    "                top_k = 6\n",
    "                idx_sorted = np.argsort(-np.abs(class_shap))[:top_k]\n",
    "                contribs = []\n",
    "                for i in idx_sorted:\n",
    "                    name = feat_names[i] if i < len(feat_names) else f\"f_{i}\"\n",
    "                    contribs.append((name, float(class_shap[i])))\n",
    "                shap_result = contribs\n",
    "    \n",
    "    # Sensitivity\n",
    "    sensitivity = sensitivity_test(resume, skill_index, project_scaler, years_scaler)\n",
    "    borderline_flag = False\n",
    "    if abs(sensitivity[\"base\"][\"confidence\"] - np.max([v[\"confidence\"] for v in sensitivity[\"perturbations\"].values()])) > 0.2:\n",
    "        borderline_flag = True\n",
    "    \n",
    "    # Compose final JSON-like explanation\n",
    "    explanation = {\n",
    "        \"id\": resume.get(\"id\"),\n",
    "        \"predicted_label\": pred_label,\n",
    "        \"predicted_confidence\": pred_conf,\n",
    "        \"rule_based_explanation\": rule_text,\n",
    "        \"matched_skills\": resume.get(\"matched_skills\", matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])[0]),\n",
    "        \"missing_skills\": resume.get(\"missing_skills\", matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])[1]),\n",
    "        \"feature_summary\": {\n",
    "            \"skill_match_ratio\": matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])[2],\n",
    "            \"years_experience\": sum([e.get(\"years\",0) for e in resume.get(\"work_experience\",[])]),\n",
    "            \"project_count\": len(resume.get(\"projects\",[])),\n",
    "            \"test_score\": resume.get(\"test_score\")\n",
    "        },\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"borderline_flag\": borderline_flag,\n",
    "        \"shap_top_contributions\": shap_result\n",
    "    }\n",
    "    return explanation\n",
    "\n",
    "# ================================\n",
    "# Example usage\n",
    "# ================================\n",
    "\n",
    "# Choose a sample resume from the cleaned/balanced dataset\n",
    "sample_resume = balanced_resumes[0]   # or final_resumes[0], etc.\n",
    "\n",
    "# Provide a small background list for SHAP (optional)\n",
    "background = balanced_resumes[1:101] if len(balanced_resumes) > 101 else balanced_resumes[:50]\n",
    "\n",
    "# Generate explanation (without SHAP)\n",
    "explanation = explain_resume(sample_resume, skill_index, project_scaler, years_scaler, background_resumes_for_shap=background, use_shap=False)\n",
    "print(\"\\n--- Rule-based explanation (short) ---\\n\")\n",
    "print(\"\\n\".join(textwrap.wrap(explanation[\"rule_based_explanation\"], width=120)))\n",
    "\n",
    "# If you have shap installed and want SHAP attribution (slower), set use_shap=True\n",
    "# explanation_shap = explain_resume(sample_resume, skill_index, project_scaler, years_scaler, background_resumes_for_shap=background, shap_nsamples=100, use_shap=True)\n",
    "# print(\"SHAP contributions:\", explanation_shap[\"shap_top_contributions\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32a3ec82-d3b4-42ff-886d-851368d77e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final JSON Output ===\n",
      "{\n",
      "  \"id\": \"candidate_0000\",\n",
      "  \"label\": \"Partial Fit\",\n",
      "  \"confidence\": 0.561,\n",
      "  \"matched_skills\": [],\n",
      "  \"missing_skills\": [\n",
      "    \"Linux\",\n",
      "    \"Kubernetes\",\n",
      "    \"Azure\",\n",
      "    \"Terraform\",\n",
      "    \"AWS\",\n",
      "    \"CI/CD\",\n",
      "    \"Docker\"\n",
      "  ],\n",
      "  \"feature_summary\": {\n",
      "    \"skill_match_ratio\": 0.0,\n",
      "    \"years_experience\": 5.0,\n",
      "    \"test_score\": 0.54,\n",
      "    \"project_count\": 2\n",
      "  },\n",
      "  \"explanation\": \"Predicted label: Partial Fit (model confidence: 0.56)\\nRaw test score: 54 / 100 (normalized: 0.54)\\nSkill match: 0 / 7 \\u2192 ratio 0.00\\nProjects: 2; Years experience (sum): 5.0\\nTop missing required skills: Linux, Kubernetes, Azure\\nRecommendations: Add containerization (Docker) example or CI/CD step.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 9 â€” Postprocessing: Final JSON Output\n",
    "# ================================\n",
    "\n",
    "def build_final_output(resume, skill_index, project_scaler, years_scaler, label_encoder, use_shap=False):\n",
    "    # Run explanation function (which also predicts)\n",
    "    explanation = explain_resume(\n",
    "        resume,\n",
    "        skill_index,\n",
    "        project_scaler,\n",
    "        years_scaler,\n",
    "        background_resumes_for_shap=None,\n",
    "        use_shap=use_shap\n",
    "    )\n",
    "    \n",
    "    # Format final JSON\n",
    "    output_json = {\n",
    "        \"id\": resume.get(\"id\"),\n",
    "        \"label\": explanation[\"predicted_label\"],\n",
    "        \"confidence\": round(explanation[\"predicted_confidence\"], 3),\n",
    "        \"matched_skills\": explanation[\"matched_skills\"],\n",
    "        \"missing_skills\": explanation[\"missing_skills\"],\n",
    "        \"feature_summary\": {\n",
    "            \"skill_match_ratio\": round(explanation[\"feature_summary\"][\"skill_match_ratio\"], 2),\n",
    "            \"years_experience\": explanation[\"feature_summary\"][\"years_experience\"],\n",
    "            \"test_score\": round(explanation[\"feature_summary\"][\"test_score\"] / 100, 2),  # normalized\n",
    "            \"project_count\": explanation[\"feature_summary\"][\"project_count\"]\n",
    "        },\n",
    "        \"explanation\": explanation[\"rule_based_explanation\"]\n",
    "    }\n",
    "    \n",
    "    return output_json\n",
    "\n",
    "\n",
    "# Example usage with one candidate\n",
    "sample_resume = balanced_resumes[0]\n",
    "final_json = build_final_output(sample_resume, skill_index, project_scaler, years_scaler, label_encoder, use_shap=False)\n",
    "\n",
    "import json\n",
    "print(\"=== Final JSON Output ===\")\n",
    "print(json.dumps(final_json, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4324bc73-a4df-4ea5-a829-766f98cf58b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model & artifacts saved in 'models/' directory\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 10 â€” Save Model & Artifacts\n",
    "# ================================\n",
    "import joblib\n",
    "\n",
    "# Save model (TensorFlow SavedModel format)\n",
    "# Save final model in .keras format\n",
    "model.save(\"models/resume_classifier.keras\")\n",
    "\n",
    "\n",
    "# Save scalers\n",
    "joblib.dump(project_scaler, \"models/project_scaler.pkl\")\n",
    "joblib.dump(years_scaler, \"models/years_scaler.pkl\")\n",
    "\n",
    "# Save skill vocabulary\n",
    "with open(\"models/skill_vocab.json\", \"w\") as f:\n",
    "    json.dump(skill_vocab, f, indent=2)\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(label_encoder, \"models/label_encoder.pkl\")\n",
    "\n",
    "# Optional: save explanation templates or SHAP background set\n",
    "# Optional: save explanation templates or SHAP background set\n",
    "with open(\"models/explanation_template.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\n",
    "        \"Template: High test score ({score}) and covers {matched}/{total} required skills. \"\n",
    "        \"Missing {missing}. Projects: {projects}; Experience: {experience} years. \"\n",
    "        \"Confidence: {confidence:.2f} â†’ {label}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"âœ… Model & artifacts saved in 'models/' directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547fac7-6d09-42e6-b204-4a85faa1f083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "691b291d-3bb2-437d-85fb-f5814dad58a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and artifacts...\n",
      "âœ… Artifacts loaded.\n",
      "âœ… Predictions completed for 5 resumes and saved to data/predictions.json\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 11 â€” Test New Resumes\n",
    "# ================================\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load saved artifacts\n",
    "# -------------------------------\n",
    "print(\"Loading model and artifacts...\")\n",
    "model = keras.models.load_model(\"models/resume_classifier.keras\")\n",
    "project_scaler = joblib.load(\"models/project_scaler.pkl\")\n",
    "years_scaler = joblib.load(\"models/years_scaler.pkl\")\n",
    "with open(\"models/skill_vocab.json\", \"r\") as f:\n",
    "    skill_vocab = json.load(f)\n",
    "skill_index = {s: i for i, s in enumerate(skill_vocab)}\n",
    "label_encoder = joblib.load(\"models/label_encoder.pkl\")\n",
    "\n",
    "print(\"âœ… Artifacts loaded.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Helper functions (from Step 3 & 4)\n",
    "# -------------------------------\n",
    "\n",
    "def encode_skills(candidate_skills, skill_index):\n",
    "    vector = np.zeros(len(skill_index), dtype=int)\n",
    "    for s in candidate_skills:\n",
    "        if s in skill_index:\n",
    "            vector[skill_index[s]] = 1\n",
    "    return vector\n",
    "\n",
    "def matched_missing_skills(candidate_skills, domain_required_skills):\n",
    "    candidate_set = set(candidate_skills)\n",
    "    required_set = set(domain_required_skills)\n",
    "    matched = list(candidate_set.intersection(required_set))\n",
    "    missing = list(required_set - candidate_set)\n",
    "    ratio = len(matched) / len(required_set) if required_set else 0\n",
    "    return matched, missing, round(ratio, 2)\n",
    "\n",
    "def extract_project_experience_features(resume):\n",
    "    project_count = len(resume.get(\"projects\", []))\n",
    "    years_experience = sum(item.get(\"years\", 0) for item in resume.get(\"work_experience\", []))\n",
    "    return project_count, years_experience\n",
    "\n",
    "def normalize_test_score(score):\n",
    "    return round(score / 100, 2)\n",
    "\n",
    "def transform_numeric_features(resume, project_scaler, years_scaler):\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    project_scaled = project_scaler.transform([[project_count]])[0][0]\n",
    "    years_scaled = years_scaler.transform([[years_exp]])[0][0]\n",
    "    return project_scaled, years_scaled\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Build final vector & predict\n",
    "# -------------------------------\n",
    "\n",
    "def build_flat_vector(resume, skill_index, project_scaler, years_scaler, domain_requirements):\n",
    "    skill_vec = encode_skills(resume[\"skills\"], skill_index)\n",
    "    domain = resume[\"preferred_domain\"]\n",
    "    _, _, ratio = matched_missing_skills(resume[\"skills\"], domain_requirements[domain][\"required_skills\"])\n",
    "    skill_features = np.append(skill_vec, ratio).astype(float)\n",
    "\n",
    "    project_scaled, years_scaled = transform_numeric_features(resume, project_scaler, years_scaler)\n",
    "    test_score_norm = normalize_test_score(resume.get(\"test_score\", 0))\n",
    "    numeric_vector = np.array([test_score_norm, project_scaled, years_scaled, ratio], dtype=float)\n",
    "\n",
    "    flat_vector = np.concatenate([skill_features, numeric_vector])\n",
    "    return flat_vector\n",
    "\n",
    "def predict_resume(resume, domain_requirements):\n",
    "    flat = build_flat_vector(resume, skill_index, project_scaler, years_scaler, domain_requirements)\n",
    "    V_plus_ratio = len(skill_vocab) + 1\n",
    "    skill_input = flat[:V_plus_ratio].reshape(1, -1)\n",
    "    numeric_input = flat[V_plus_ratio:V_plus_ratio + 4].reshape(1, -1)\n",
    "    probs = model.predict({\"skill_input\": skill_input, \"numeric_input\": numeric_input}, verbose=0)\n",
    "    pred_idx = int(np.argmax(probs))\n",
    "    pred_label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "    confidence = float(np.max(probs))\n",
    "    matched, missing, _ = matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    return {\n",
    "        \"id\": resume.get(\"id\"),\n",
    "        \"label\": pred_label,\n",
    "        \"confidence\": round(confidence, 3),\n",
    "        \"matched_skills\": matched,\n",
    "        \"missing_skills\": missing,\n",
    "        \"feature_summary\": {\n",
    "            \"skill_match_ratio\": round(len(matched) / len(domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"]), 2),\n",
    "            \"years_experience\": years_exp,\n",
    "            \"test_score\": round(normalize_test_score(resume.get(\"test_score\", 0)), 2),\n",
    "            \"project_count\": project_count\n",
    "        }\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Load new resumes dataset\n",
    "# -------------------------------\n",
    "with open(\"data/new_resumes.json\", \"r\") as f:\n",
    "    new_resumes = json.load(f)\n",
    "\n",
    "# Replace this with your actual domain requirements\n",
    "with open(\"data/domain_requirements/data_science.json\") as f:\n",
    "    data_science_req = json.load(f)\n",
    "with open(\"data/domain_requirements/web_development.json\") as f:\n",
    "    web_req = json.load(f)\n",
    "with open(\"data/domain_requirements/cloud_engineering.json\") as f:\n",
    "    cloud_req = json.load(f)\n",
    "domain_requirements = {\n",
    "    \"Data Science\": data_science_req,\n",
    "    \"Web Development\": web_req,\n",
    "    \"Cloud Engineering\": cloud_req\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Predict & save\n",
    "# -------------------------------\n",
    "results = []\n",
    "for resume in new_resumes:\n",
    "    output = predict_resume(resume, domain_requirements)\n",
    "    results.append(output)\n",
    "\n",
    "with open(\"data/predictions.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Predictions completed for {len(results)} resumes and saved to data/predictions.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad5aaee-9175-4279-bc78-44806c596a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and artifacts...\n",
      "âœ… Artifacts loaded.\n",
      "âœ… Predictions with explanations completed for 5 resumes and saved to data/predictions.json\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 11 â€” Test New Resumes (with explanations)\n",
    "# ================================\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load saved artifacts\n",
    "# -------------------------------\n",
    "print(\"Loading model and artifacts...\")\n",
    "model = keras.models.load_model(\"models/resume_classifier.keras\")\n",
    "project_scaler = joblib.load(\"models/project_scaler.pkl\")\n",
    "years_scaler = joblib.load(\"models/years_scaler.pkl\")\n",
    "with open(\"models/skill_vocab.json\", \"r\") as f:\n",
    "    skill_vocab = json.load(f)\n",
    "skill_index = {s: i for i, s in enumerate(skill_vocab)}\n",
    "label_encoder = joblib.load(\"models/label_encoder.pkl\")\n",
    "print(\"âœ… Artifacts loaded.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load new resumes dataset\n",
    "# -------------------------------\n",
    "with open(\"data/new_resumes.json\", \"r\") as f:\n",
    "    new_resumes = json.load(f)\n",
    "\n",
    "# Load domain requirements\n",
    "with open(\"data/domain_requirements/data_science.json\") as f:\n",
    "    data_science_req = json.load(f)\n",
    "with open(\"data/domain_requirements/web_development.json\") as f:\n",
    "    web_req = json.load(f)\n",
    "with open(\"data/domain_requirements/cloud_engineering.json\") as f:\n",
    "    cloud_req = json.load(f)\n",
    "\n",
    "domain_requirements = {\n",
    "    \"Data Science\": data_science_req,\n",
    "    \"Web Development\": web_req,\n",
    "    \"Cloud Engineering\": cloud_req\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Predict & build final JSON output\n",
    "# -------------------------------\n",
    "results = []\n",
    "for resume in new_resumes:\n",
    "    output_json = build_final_output(\n",
    "        resume,\n",
    "        skill_index,\n",
    "        project_scaler,\n",
    "        years_scaler,\n",
    "        label_encoder,\n",
    "        use_shap=False  # set True if SHAP is installed and desired\n",
    "    )\n",
    "    results.append(output_json)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Save predictions\n",
    "# -------------------------------\n",
    "with open(\"data/predictions.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Predictions with explanations completed for {len(results)} resumes and saved to data/predictions.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708493e-f164-49c8-ae67-85183efa7243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
