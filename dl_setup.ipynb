{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1478532c-329c-4894-afc0-802da75f8dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Project structure created: ['data', 'models', 'notebooks', 'src']\n",
      "âœ… Seeds fixed to: 42\n",
      "ğŸ“¦ Suggested packages: ['numpy', 'pandas', 'scikit-learn', 'tensorflow', 'nltk', 'spacy', 'sentence-transformers', 'shap', 'lime', 'matplotlib']\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 0 â€” Project Setup\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define project structure\n",
    "project_dirs = [\"data\", \"models\", \"notebooks\", \"src\"]\n",
    "\n",
    "for d in project_dirs:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Project structure created:\", project_dirs)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"âœ… Seeds fixed to:\", seed)\n",
    "\n",
    "# Verify packages (if running fresh environment)\n",
    "required_packages = [\n",
    "    \"numpy\", \"pandas\", \"scikit-learn\", \"tensorflow\", \n",
    "    \"nltk\", \"spacy\", \"sentence-transformers\", \"shap\", \"lime\", \"matplotlib\"\n",
    "]\n",
    "print(\"ğŸ“¦ Suggested packages:\", required_packages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9420ad4-b7b8-45f9-8fe0-d6046d233dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Domain requirement files saved.\n",
      "âœ… Generated 2000 synthetic resumes and saved to data/synthetic_resumes.json\n",
      "{\n",
      "  \"id\": \"candidate_0000\",\n",
      "  \"skills\": [\n",
      "    \"SQL\",\n",
      "    \"Express\",\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Deep Learning\",\n",
      "    \"CI/CD\"\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    \"Image Classification using CNN\",\n",
      "    \"ETL Pipeline with Spark\"\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"title\": \"Cloud Engineer\",\n",
      "      \"years\": 2\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Backend Developer\",\n",
      "      \"years\": 3\n",
      "    }\n",
      "  ],\n",
      "  \"test_score\": 54,\n",
      "  \"preferred_domain\": \"Cloud Engineering\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 1 â€” Generate / Collect Dataset\n",
    "# ================================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- 1.2 Domain Requirements ----------\n",
    "domain_requirements = {\n",
    "    \"Data Science\": {\n",
    "        \"domain\": \"Data Science\",\n",
    "        \"required_skills\": [\n",
    "            \"Python\", \"Pandas\", \"NumPy\", \"Scikit-learn\", \"PyTorch\", \"Docker\", \"Deep Learning\"\n",
    "        ]\n",
    "    },\n",
    "    \"Web Development\": {\n",
    "        \"domain\": \"Web Development\",\n",
    "        \"required_skills\": [\n",
    "            \"HTML\", \"CSS\", \"JavaScript\", \"React\", \"Node.js\", \"Express\", \"SQL\"\n",
    "        ]\n",
    "    },\n",
    "    \"Cloud Engineering\": {\n",
    "        \"domain\": \"Cloud Engineering\",\n",
    "        \"required_skills\": [\n",
    "            \"AWS\", \"Azure\", \"Docker\", \"Kubernetes\", \"Linux\", \"Terraform\", \"CI/CD\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save domain requirement files\n",
    "os.makedirs(\"data/domain_requirements\", exist_ok=True)\n",
    "for domain, req in domain_requirements.items():\n",
    "    with open(f\"data/domain_requirements/{domain.lower().replace(' ','_')}.json\", \"w\") as f:\n",
    "        json.dump(req, f, indent=4)\n",
    "\n",
    "print(\"âœ… Domain requirement files saved.\")\n",
    "\n",
    "\n",
    "# ---------- 1.3 Synthetic Resume Generator ----------\n",
    "skills_pool = list(set(sum([req[\"required_skills\"] for req in domain_requirements.values()], []))) + [\n",
    "    \"C++\", \"Java\", \"SQL\", \"Tableau\", \"Hadoop\", \"Spark\", \"Flask\"\n",
    "]\n",
    "\n",
    "job_titles = [\"Data Scientist\", \"Data Analyst\", \"ML Engineer\", \"Backend Developer\", \"Frontend Developer\", \"Cloud Engineer\"]\n",
    "\n",
    "projects_pool = [\n",
    "    \"Image Classification using CNN\", \"Web Scraping with Python\", \"Portfolio Website\",\n",
    "    \"Cloud Infrastructure Setup\", \"ETL Pipeline with Spark\", \"Dashboard with React\"\n",
    "]\n",
    "\n",
    "def generate_resume(idx, domains):\n",
    "    domain = np.random.choice(list(domains.keys()))\n",
    "    required = domains[domain][\"required_skills\"]\n",
    "\n",
    "    # Randomly sample skills\n",
    "    n_skills = np.random.randint(3, 10)\n",
    "    skills = list(np.random.choice(skills_pool, n_skills, replace=False))\n",
    "\n",
    "    # Projects\n",
    "    n_projects = np.random.randint(0, 4)\n",
    "    projects = list(np.random.choice(projects_pool, n_projects, replace=False))\n",
    "\n",
    "    # Work experience\n",
    "    n_exp = np.random.randint(1, 3)\n",
    "    work_experience = [\n",
    "        {\"title\": np.random.choice(job_titles), \"years\": np.random.randint(0, 6)}\n",
    "        for _ in range(n_exp)\n",
    "    ]\n",
    "\n",
    "    # Test score from clipped normal distribution (mean=65, std=20)\n",
    "    test_score = int(np.clip(np.random.normal(65, 20), 0, 100))\n",
    "\n",
    "    resume = {\n",
    "        \"id\": f\"candidate_{idx:04d}\",\n",
    "        \"skills\": skills,\n",
    "        \"projects\": projects,\n",
    "        \"work_experience\": work_experience,\n",
    "        \"test_score\": test_score,\n",
    "        \"preferred_domain\": domain\n",
    "    }\n",
    "    return resume\n",
    "\n",
    "\n",
    "# Generate N=2000 synthetic resumes\n",
    "N = 2000\n",
    "synthetic_resumes = [generate_resume(i, domain_requirements) for i in range(N)]\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"data/synthetic_resumes.json\", \"w\") as f:\n",
    "    json.dump(synthetic_resumes, f, indent=4)\n",
    "\n",
    "print(f\"âœ… Generated {N} synthetic resumes and saved to data/synthetic_resumes.json\")\n",
    "\n",
    "# Quick peek at one sample\n",
    "print(json.dumps(synthetic_resumes[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a4cb07d-8805-4e60-ab79-25d6c9545eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rule-based labels assigned and saved to data/labeled_resumes.json\n",
      "\n",
      "Label Distribution:\n",
      " Partial Fit    1173\n",
      "Not Fit         826\n",
      "Fit               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample Resume with Label:\n",
      " {\n",
      "  \"id\": \"candidate_0000\",\n",
      "  \"skills\": [\n",
      "    \"SQL\",\n",
      "    \"Express\",\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Deep Learning\",\n",
      "    \"CI/CD\"\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    \"Image Classification using CNN\",\n",
      "    \"ETL Pipeline with Spark\"\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"title\": \"Cloud Engineer\",\n",
      "      \"years\": 2\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Backend Developer\",\n",
      "      \"years\": 3\n",
      "    }\n",
      "  ],\n",
      "  \"test_score\": 54,\n",
      "  \"preferred_domain\": \"Cloud Engineering\",\n",
      "  \"matched_skills\": [\n",
      "    \"CI/CD\"\n",
      "  ],\n",
      "  \"missing_skills\": [\n",
      "    \"AWS\",\n",
      "    \"Kubernetes\",\n",
      "    \"Terraform\",\n",
      "    \"Azure\",\n",
      "    \"Linux\",\n",
      "    \"Docker\"\n",
      "  ],\n",
      "  \"skill_match_ratio\": 0.14,\n",
      "  \"test_score_norm\": 0.54,\n",
      "  \"project_count\": 2,\n",
      "  \"label\": \"Partial Fit\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 2 â€” Create Ground Truth Labels (Rule-based)\n",
    "# ================================\n",
    "\n",
    "# Load domain requirements\n",
    "domain_req_map = {}\n",
    "for domain, req in domain_requirements.items():\n",
    "    domain_req_map[domain] = set(req[\"required_skills\"])\n",
    "\n",
    "def assign_label(resume, domain_req_map):\n",
    "    domain = resume[\"preferred_domain\"]\n",
    "    required_skills = domain_req_map[domain]\n",
    "    candidate_skills = set(resume[\"skills\"])\n",
    "\n",
    "    # Matched & missing skills\n",
    "    matched_skills = candidate_skills.intersection(required_skills)\n",
    "    missing_skills = required_skills - candidate_skills\n",
    "\n",
    "    # Ratios & counts\n",
    "    skill_match_ratio = len(matched_skills) / len(required_skills) if required_skills else 0\n",
    "    test_score_norm = resume[\"test_score\"] / 100\n",
    "    project_count = len(resume[\"projects\"])\n",
    "\n",
    "    # Apply labeling rules\n",
    "    if (skill_match_ratio >= 0.70) and (test_score_norm >= 0.75) and (project_count >= 1):\n",
    "        label = \"Fit\"\n",
    "    elif (0.40 <= skill_match_ratio < 0.70) or (0.50 <= test_score_norm < 0.75):\n",
    "        label = \"Partial Fit\"\n",
    "    else:\n",
    "        label = \"Not Fit\"\n",
    "\n",
    "    # Add extra fields\n",
    "    resume[\"matched_skills\"] = list(matched_skills)\n",
    "    resume[\"missing_skills\"] = list(missing_skills)\n",
    "    resume[\"skill_match_ratio\"] = round(skill_match_ratio, 2)\n",
    "    resume[\"test_score_norm\"] = round(test_score_norm, 2)\n",
    "    resume[\"project_count\"] = project_count\n",
    "    resume[\"label\"] = label\n",
    "\n",
    "    return resume\n",
    "\n",
    "\n",
    "# Apply labeling to all resumes\n",
    "labeled_resumes = [assign_label(r, domain_req_map) for r in synthetic_resumes]\n",
    "\n",
    "# Save labeled dataset\n",
    "with open(\"data/labeled_resumes.json\", \"w\") as f:\n",
    "    json.dump(labeled_resumes, f, indent=4)\n",
    "\n",
    "print(\"âœ… Rule-based labels assigned and saved to data/labeled_resumes.json\")\n",
    "\n",
    "# Quick distribution check\n",
    "label_counts = pd.Series([r[\"label\"] for r in labeled_resumes]).value_counts()\n",
    "print(\"\\nLabel Distribution:\\n\", label_counts)\n",
    "\n",
    "# Peek at one labeled resume\n",
    "print(\"\\nSample Resume with Label:\\n\", json.dumps(labeled_resumes[0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b2e680d-54f0-450e-a7d8-4a94b3d2732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned dataset: 2000 resumes (from 2000)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step A â€” Data Cleaning after Generation\n",
    "# ================================\n",
    "\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Canonical vocab (from domain requirements)\n",
    "canonical_skills = sorted(set(sum([req[\"required_skills\"] for req in domain_requirements.values()], [])))\n",
    "\n",
    "# Stopwords for projects\n",
    "stopwords = {\"and\", \"the\", \"project\", \"using\"}\n",
    "\n",
    "# Canonical job titles\n",
    "canonical_titles = [\"data scientist\", \"data analyst\", \"machine learning engineer\", \"intern\", \n",
    "                    \"backend developer\", \"frontend developer\", \"cloud engineer\"]\n",
    "\n",
    "def normalize_skill(skill, canonical_vocab):\n",
    "    s = skill.strip().lower()\n",
    "    # Try exact canonical match\n",
    "    if s in [c.lower() for c in canonical_vocab]:\n",
    "        return s\n",
    "    # Try fuzzy matching (closest skill)\n",
    "    match = get_close_matches(s, [c.lower() for c in canonical_vocab], n=1, cutoff=0.8)\n",
    "    if match:\n",
    "        return match[0]\n",
    "    return s   # keep as-is if no good match\n",
    "\n",
    "def clean_projects(projects):\n",
    "    cleaned = []\n",
    "    for p in projects:\n",
    "        p = p.lower()\n",
    "        p = re.sub(r\"[^a-z0-9 ]\", \" \", p)  # remove punctuation\n",
    "        tokens = [t for t in p.split() if t not in stopwords]\n",
    "        if len(tokens) >= 2:\n",
    "            cleaned.append(\" \".join(tokens))\n",
    "    return list(set(cleaned))  # deduplicate\n",
    "\n",
    "def normalize_title(title):\n",
    "    t = title.lower().strip()\n",
    "    match = get_close_matches(t, canonical_titles, n=1, cutoff=0.7)\n",
    "    return match[0] if match else t\n",
    "\n",
    "def clean_years(years):\n",
    "    try:\n",
    "        y = float(re.sub(\"[^0-9.]\", \"\", str(years)))\n",
    "        return max(y, 0)  # clamp negatives\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def clean_resume(resume):\n",
    "    # Skills\n",
    "    resume[\"skills\"] = list({normalize_skill(s, canonical_skills) for s in resume[\"skills\"]})\n",
    "    \n",
    "    # Projects\n",
    "    resume[\"projects\"] = clean_projects(resume[\"projects\"])\n",
    "    \n",
    "    # Work experience\n",
    "    cleaned_exp = []\n",
    "    for exp in resume[\"work_experience\"]:\n",
    "        cleaned_exp.append({\n",
    "            \"title\": normalize_title(exp[\"title\"]),\n",
    "            \"years\": clean_years(exp[\"years\"])\n",
    "        })\n",
    "    resume[\"work_experience\"] = cleaned_exp\n",
    "    \n",
    "    # Test score\n",
    "    score = resume.get(\"test_score\", 0)\n",
    "    score = max(0, min(score, 100))  # clamp\n",
    "    resume[\"test_score\"] = int(score)\n",
    "    resume[\"test_score_norm\"] = round(score/100, 2)\n",
    "    \n",
    "    return resume\n",
    "\n",
    "# Apply cleaning\n",
    "cleaned_resumes = [clean_resume(r) for r in labeled_resumes]\n",
    "\n",
    "# Remove corrupted/duplicates\n",
    "seen = set()\n",
    "final_resumes = []\n",
    "for r in cleaned_resumes:\n",
    "    key = (tuple(sorted(r[\"skills\"])), tuple(r[\"projects\"]), r[\"test_score\"], r[\"preferred_domain\"])\n",
    "    if not r[\"skills\"] and not r[\"projects\"] and r[\"test_score\"] == 0:\n",
    "        continue  # drop corrupted\n",
    "    if r[\"preferred_domain\"] == \"\":\n",
    "        continue\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    final_resumes.append(r)\n",
    "\n",
    "print(f\"âœ… Cleaned dataset: {len(final_resumes)} resumes (from {len(labeled_resumes)})\")\n",
    "\n",
    "# Save cleaned data\n",
    "with open(\"data/cleaned_resumes.json\", \"w\") as f:\n",
    "    json.dump(final_resumes, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9b01943-4b1c-460b-888f-c7547fb17392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing: Counter({'Partial Fit': 1173, 'Not Fit': 826, 'Fit': 1})\n",
      "After balancing: Counter({'Partial Fit': 1173, 'Not Fit': 1173, 'Fit': 1173})\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step B â€” Label Balancing\n",
    "# ================================\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "labels = [r[\"label\"] for r in final_resumes]\n",
    "counts = Counter(labels)\n",
    "print(\"Before balancing:\", counts)\n",
    "\n",
    "max_count = max(counts.values())\n",
    "balanced_resumes = []\n",
    "\n",
    "for label, count in counts.items():\n",
    "    group = [r for r in final_resumes if r[\"label\"] == label]\n",
    "    if count < max_count:\n",
    "        # Oversample minority\n",
    "        extra = random.choices(group, k=max_count - count)\n",
    "        balanced_resumes.extend(group + extra)\n",
    "    else:\n",
    "        balanced_resumes.extend(group)\n",
    "\n",
    "balanced_counts = Counter([r[\"label\"] for r in balanced_resumes])\n",
    "print(\"After balancing:\", balanced_counts)\n",
    "\n",
    "# Save balanced dataset\n",
    "with open(\"data/balanced_resumes.json\", \"w\") as f:\n",
    "    json.dump(balanced_resumes, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36a1eaa5-aea5-499b-a1a6-00f62437a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Built skill vocabulary of size 46\n",
      "\n",
      "=== Sample Resume Features ===\n",
      "Skill vector length: 46\n",
      "Matched: []\n",
      "Missing: ['AWS', 'Kubernetes', 'Terraform', 'Azure', 'Linux', 'CI/CD', 'Docker']\n",
      "Skill match ratio: 0.0\n",
      "Project count: 2 â†’ scaled: 0.43\n",
      "Years experience: 5.0 â†’ scaled: 0.5\n",
      "Normalized test score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 3 â€” Preprocessing & Helper Functions\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 3.1 Build skill vocabulary\n",
    "def build_skill_vocab(resumes, domain_requirements):\n",
    "    all_skills = set()\n",
    "    for r in resumes:\n",
    "        all_skills.update(r[\"skills\"])\n",
    "    for domain, req in domain_requirements.items():\n",
    "        all_skills.update(req[\"required_skills\"])\n",
    "    skill_vocab = sorted(all_skills)\n",
    "    return skill_vocab\n",
    "\n",
    "skill_vocab = build_skill_vocab(final_resumes, domain_requirements)\n",
    "skill_index = {s: i for i, s in enumerate(skill_vocab)}\n",
    "skill_vocab_size = len(skill_vocab)\n",
    "\n",
    "print(f\"âœ… Built skill vocabulary of size {skill_vocab_size}\")\n",
    "\n",
    "\n",
    "# 3.2 Skill encoding function\n",
    "def encode_skills(candidate_skills, skill_index):\n",
    "    vector = np.zeros(len(skill_index), dtype=int)\n",
    "    for s in candidate_skills:\n",
    "        if s in skill_index:\n",
    "            vector[skill_index[s]] = 1\n",
    "    return vector\n",
    "\n",
    "\n",
    "# 3.3 Matched & missing skills\n",
    "def matched_missing_skills(candidate_skills, domain_required_skills):\n",
    "    candidate_set = set(candidate_skills)\n",
    "    required_set = set(domain_required_skills)\n",
    "    matched = list(candidate_set.intersection(required_set))\n",
    "    missing = list(required_set - candidate_set)\n",
    "    ratio = len(matched) / len(required_set) if required_set else 0\n",
    "    return matched, missing, round(ratio, 2)\n",
    "\n",
    "\n",
    "# 3.4 Project & experience features\n",
    "def extract_project_experience_features(resume):\n",
    "    project_count = len(resume.get(\"projects\", []))\n",
    "    years_experience = sum(item.get(\"years\", 0) for item in resume.get(\"work_experience\", []))\n",
    "    return project_count, years_experience\n",
    "\n",
    "\n",
    "# 3.5 Test score normalization\n",
    "def normalize_test_score(score):\n",
    "    return round(score / 100, 2)\n",
    "\n",
    "\n",
    "# 3.6 Numeric feature scaling (fit & transform on dataset)\n",
    "def fit_numeric_scalers(resumes):\n",
    "    project_counts = []\n",
    "    years_exp = []\n",
    "    \n",
    "    for r in resumes:\n",
    "        p, y = extract_project_experience_features(r)\n",
    "        project_counts.append(p)\n",
    "        years_exp.append(y)\n",
    "    \n",
    "    project_scaler = StandardScaler()\n",
    "    years_scaler = StandardScaler()\n",
    "    \n",
    "    project_scaler.fit(np.array(project_counts).reshape(-1, 1))\n",
    "    years_scaler.fit(np.array(years_exp).reshape(-1, 1))\n",
    "    \n",
    "    return project_scaler, years_scaler\n",
    "\n",
    "def transform_numeric_features(resume, project_scaler, years_scaler):\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    project_scaled = project_scaler.transform([[project_count]])[0][0]\n",
    "    years_scaled = years_scaler.transform([[years_exp]])[0][0]\n",
    "    return project_scaled, years_scaled\n",
    "\n",
    "\n",
    "# ================================\n",
    "# âœ… Test the helper functions\n",
    "# ================================\n",
    "# Fit scalers on dataset\n",
    "project_scaler, years_scaler = fit_numeric_scalers(final_resumes)\n",
    "\n",
    "sample = final_resumes[0]\n",
    "\n",
    "# Encode skills\n",
    "skill_vector = encode_skills(sample[\"skills\"], skill_index)\n",
    "\n",
    "# Matched & missing\n",
    "domain = sample[\"preferred_domain\"]\n",
    "matched, missing, ratio = matched_missing_skills(sample[\"skills\"], domain_requirements[domain][\"required_skills\"])\n",
    "\n",
    "# Numeric features\n",
    "p_count, y_exp = extract_project_experience_features(sample)\n",
    "p_scaled, y_scaled = transform_numeric_features(sample, project_scaler, years_scaler)\n",
    "\n",
    "# Test score norm\n",
    "score_norm = normalize_test_score(sample[\"test_score\"])\n",
    "\n",
    "print(\"\\n=== Sample Resume Features ===\")\n",
    "print(\"Skill vector length:\", len(skill_vector))\n",
    "print(\"Matched:\", matched)\n",
    "print(\"Missing:\", missing)\n",
    "print(\"Skill match ratio:\", ratio)\n",
    "print(\"Project count:\", p_count, \"â†’ scaled:\", round(p_scaled, 2))\n",
    "print(\"Years experience:\", y_exp, \"â†’ scaled:\", round(y_scaled, 2))\n",
    "print(\"Normalized test score:\", score_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2069441-7e17-4eb7-9e6e-59f5498a8026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SBERT model loaded for text embeddings\n",
      "\n",
      "=== Final Vector Details ===\n",
      "Skill vector size: 46\n",
      "Skill branch size (with ratio): 47\n",
      "Numeric branch size: 4\n",
      "Text branch size: 384\n",
      "Final vector size: 435\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 4 â€” Final Feature Vector\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    use_embeddings = True\n",
    "    print(\"âœ… SBERT model loaded for text embeddings\")\n",
    "except ImportError:\n",
    "    sbert_model = None\n",
    "    use_embeddings = False\n",
    "    print(\"âš ï¸ SentenceTransformer not installed â€” skipping text embeddings\")\n",
    "\n",
    "\n",
    "def build_final_vector(resume, domain_requirements, skill_index, \n",
    "                       project_scaler, years_scaler, use_embeddings=False):\n",
    "    \"\"\"\n",
    "    Construct final feature vector for a single resume.\n",
    "    \"\"\"\n",
    "    # 1. Skills branch\n",
    "    skill_vector = encode_skills(resume[\"skills\"], skill_index)  # binary\n",
    "    domain = resume[\"preferred_domain\"]\n",
    "    matched, missing, ratio = matched_missing_skills(resume[\"skills\"], domain_requirements[domain][\"required_skills\"])\n",
    "    \n",
    "    # Add skill_match_ratio as scalar numeric feature\n",
    "    skill_features = np.append(skill_vector, ratio)\n",
    "\n",
    "    # 2. Numeric branch\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    project_scaled, years_scaled = transform_numeric_features(resume, project_scaler, years_scaler)\n",
    "    test_score_norm = normalize_test_score(resume[\"test_score\"])\n",
    "    numeric_vector = np.array([test_score_norm, project_scaled, years_scaled, ratio])\n",
    "\n",
    "    # 3. Optional text branch (project titles & job titles)\n",
    "    if use_embeddings and sbert_model:\n",
    "        project_titles = resume.get(\"projects\", [])\n",
    "        exp_titles = [exp[\"title\"] for exp in resume.get(\"work_experience\", [])]\n",
    "        text_items = project_titles + exp_titles\n",
    "        if text_items:\n",
    "            project_embedding = np.mean(sbert_model.encode(text_items), axis=0)\n",
    "        else:\n",
    "            project_embedding = np.zeros(384)  # MiniLM embedding size\n",
    "    else:\n",
    "        project_embedding = np.array([])  # skip if not using embeddings\n",
    "\n",
    "    # 4. Concatenate all branches\n",
    "    final_vector = np.concatenate([skill_features, numeric_vector, project_embedding])\n",
    "    return final_vector\n",
    "\n",
    "\n",
    "# ================================\n",
    "# âœ… Test on a sample resume\n",
    "# ================================\n",
    "\n",
    "sample = final_resumes[0]\n",
    "final_vec = build_final_vector(sample, domain_requirements, skill_index, \n",
    "                               project_scaler, years_scaler, use_embeddings)\n",
    "\n",
    "print(\"\\n=== Final Vector Details ===\")\n",
    "print(\"Skill vector size:\", len(skill_vocab))\n",
    "print(\"Skill branch size (with ratio):\", len(skill_vocab) + 1)\n",
    "print(\"Numeric branch size:\", 4)\n",
    "if use_embeddings:\n",
    "    print(\"Text branch size:\", len(final_vec) - (len(skill_vocab) + 1 + 4))\n",
    "else:\n",
    "    print(\"Text branch skipped\")\n",
    "print(\"Final vector size:\", len(final_vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e1b6d67-119b-4585-93a8-c26517dc07a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ skill_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> â”‚ skill_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ numeric_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> â”‚ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             â”‚\n",
       "â”‚                               â”‚                           â”‚                 â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,560</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> â”‚ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ skill_input (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               â”‚          \u001b[38;5;34m12,288\u001b[0m â”‚ skill_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ numeric_input (\u001b[38;5;33mInputLayer\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                â”‚             \u001b[38;5;34m160\u001b[0m â”‚ numeric_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               â”‚          \u001b[38;5;34m32,896\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                â”‚             \u001b[38;5;34m528\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             â”‚\n",
       "â”‚                               â”‚                           â”‚                 â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               â”‚          \u001b[38;5;34m18,560\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               â”‚               \u001b[38;5;34m0\u001b[0m â”‚ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 â”‚             \u001b[38;5;34m195\u001b[0m â”‚ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,883</span> (284.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m72,883\u001b[0m (284.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,883</span> (284.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m72,883\u001b[0m (284.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 5 â€” Model Architecture\n",
    "# ================================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_resume_classifier(skill_vocab_size, numeric_size=4, text_embedding_size=None, learning_rate=1e-3):\n",
    "    \"\"\"\n",
    "    Build a hybrid Keras model for resume classification.\n",
    "    \n",
    "    Args:\n",
    "        skill_vocab_size: int â†’ number of skills in vocabulary\n",
    "        numeric_size: int â†’ number of numeric features (default 4)\n",
    "        text_embedding_size: int or None â†’ dimension of text embedding if used\n",
    "        learning_rate: float â†’ learning rate for optimizer\n",
    "    \"\"\"\n",
    "    # 5.1 Inputs\n",
    "    skill_input = Input(shape=(skill_vocab_size,), name=\"skill_input\")\n",
    "    numeric_input = Input(shape=(numeric_size,), name=\"numeric_input\")\n",
    "    inputs = [skill_input, numeric_input]\n",
    "    \n",
    "    # Optional text input\n",
    "    if text_embedding_size:\n",
    "        project_input = Input(shape=(text_embedding_size,), name=\"project_input\")\n",
    "        inputs.append(project_input)\n",
    "    else:\n",
    "        project_input = None\n",
    "    \n",
    "    # 5.2 Skills branch\n",
    "    x1 = Dense(256, activation=\"relu\")(skill_input)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    x1 = Dense(128, activation=\"relu\")(x1)\n",
    "    \n",
    "    # 5.3 Numeric branch\n",
    "    x2 = Dense(32, activation=\"relu\")(numeric_input)\n",
    "    x2 = Dense(16, activation=\"relu\")(x2)\n",
    "    \n",
    "    # 5.4 Project/text branch\n",
    "    if project_input is not None:\n",
    "        x3 = Dense(128, activation=\"relu\")(project_input)\n",
    "        x3 = Dense(64, activation=\"relu\")(x3)\n",
    "        concat = concatenate([x1, x2, x3])\n",
    "    else:\n",
    "        concat = concatenate([x1, x2])\n",
    "    \n",
    "    # 5.5 Concatenate â†’ hidden layers\n",
    "    h = Dense(128, activation=\"relu\")(concat)\n",
    "    h = Dropout(0.3)(h)\n",
    "    h = Dense(64, activation=\"relu\")(h)\n",
    "    \n",
    "    # 5.6 Output (3 classes: Fit, Partial Fit, Not Fit)\n",
    "    out = Dense(3, activation=\"softmax\", name=\"output\")(h)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    \n",
    "    # 5.7 Compile\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ================================\n",
    "# âœ… Build model (without text embeddings for now)\n",
    "# ================================\n",
    "V = skill_vocab_size + 1   # skills + ratio\n",
    "numeric_size = 4\n",
    "text_embedding_size = None   # or 384 if using SBERT embeddings\n",
    "\n",
    "model = build_resume_classifier(V, numeric_size, text_embedding_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82188bd5-2d99-4a95-be2c-6d81d606e76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2463, Val size: 528, Test size: 528\n",
      "Class weights: {0: 1.0, 1: 1.0, 2: 1.0}\n",
      "Epoch 1/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6565 - loss: 0.5660 - val_accuracy: 0.6723 - val_loss: 0.4693\n",
      "Epoch 2/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6947 - loss: 0.4641 - val_accuracy: 0.6686 - val_loss: 0.4672\n",
      "Epoch 3/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6991 - loss: 0.4572 - val_accuracy: 0.7140 - val_loss: 0.4642\n",
      "Epoch 4/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7235 - loss: 0.4520 - val_accuracy: 0.7121 - val_loss: 0.4639\n",
      "Epoch 5/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7361 - loss: 0.4381 - val_accuracy: 0.6989 - val_loss: 0.4700\n",
      "Epoch 6/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.4313 - val_accuracy: 0.7178 - val_loss: 0.4594\n",
      "Epoch 7/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7686 - loss: 0.4107 - val_accuracy: 0.7102 - val_loss: 0.4576\n",
      "Epoch 8/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.4010 - val_accuracy: 0.7216 - val_loss: 0.4569\n",
      "Epoch 9/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.3798 - val_accuracy: 0.7102 - val_loss: 0.4553\n",
      "Epoch 10/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 0.3595 - val_accuracy: 0.7216 - val_loss: 0.4757\n",
      "Epoch 11/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8400 - loss: 0.3297 - val_accuracy: 0.7500 - val_loss: 0.4799\n",
      "Epoch 12/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.3032 - val_accuracy: 0.7519 - val_loss: 0.5064\n",
      "Epoch 13/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8652 - loss: 0.2912 - val_accuracy: 0.7652 - val_loss: 0.4701\n",
      "Epoch 14/50\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8814 - loss: 0.2572 - val_accuracy: 0.7822 - val_loss: 0.4919\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 6 â€” Training Procedure\n",
    "# ================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare dataset (features + labels)\n",
    "# -------------------------------\n",
    "def prepare_dataset(resumes, domain_requirements, skill_index, project_scaler, years_scaler, use_embeddings=False):\n",
    "    X_skills, X_numeric, X_text, y = [], [], [], []\n",
    "    \n",
    "    for r in resumes:\n",
    "        # Skill branch (skills + ratio already included in build_final_vector)\n",
    "        skill_vector = encode_skills(r[\"skills\"], skill_index)\n",
    "        domain = r[\"preferred_domain\"]\n",
    "        _, _, ratio = matched_missing_skills(r[\"skills\"], domain_requirements[domain][\"required_skills\"])\n",
    "        skill_features = np.append(skill_vector, ratio)\n",
    "        \n",
    "        # Numeric branch\n",
    "        project_scaled, years_scaled = transform_numeric_features(r, project_scaler, years_scaler)\n",
    "        test_score_norm = normalize_test_score(r[\"test_score\"])\n",
    "        numeric_vector = np.array([test_score_norm, project_scaled, years_scaled, ratio])\n",
    "        \n",
    "        # Optional text branch\n",
    "        if use_embeddings and sbert_model:\n",
    "            project_titles = r.get(\"projects\", [])\n",
    "            exp_titles = [exp[\"title\"] for exp in r.get(\"work_experience\", [])]\n",
    "            text_items = project_titles + exp_titles\n",
    "            if text_items:\n",
    "                project_embedding = np.mean(sbert_model.encode(text_items), axis=0)\n",
    "            else:\n",
    "                project_embedding = np.zeros(384)\n",
    "        else:\n",
    "            project_embedding = None\n",
    "        \n",
    "        X_skills.append(skill_features)\n",
    "        X_numeric.append(numeric_vector)\n",
    "        if use_embeddings:\n",
    "            X_text.append(project_embedding)\n",
    "        y.append(r[\"label\"])\n",
    "    \n",
    "    X_skills = np.array(X_skills)\n",
    "    X_numeric = np.array(X_numeric)\n",
    "    if use_embeddings:\n",
    "        X_text = np.array(X_text)\n",
    "    else:\n",
    "        X_text = None\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    y_onehot = to_categorical(y_encoded, num_classes=3)\n",
    "    \n",
    "    return X_skills, X_numeric, X_text, y_onehot, label_encoder\n",
    "\n",
    "\n",
    "# Load balanced dataset\n",
    "with open(\"data/balanced_resumes.json\", \"r\") as f:\n",
    "    balanced_resumes = json.load(f)\n",
    "\n",
    "X_skills, X_numeric, X_text, y, label_encoder = prepare_dataset(\n",
    "    balanced_resumes, domain_requirements, skill_index, project_scaler, years_scaler, use_embeddings=False\n",
    ")\n",
    "\n",
    "# Train/val/test split (70/15/15 stratified)\n",
    "X_train_s, X_temp_s, X_train_n, X_temp_n, y_train, y_temp = train_test_split(\n",
    "    X_skills, X_numeric, y, test_size=0.30, stratify=y, random_state=42\n",
    ")\n",
    "X_val_s, X_test_s, X_val_n, X_test_n, y_val, y_test = train_test_split(\n",
    "    X_temp_s, X_temp_n, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train_s)}, Val size: {len(X_val_s)}, Test size: {len(X_test_s)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Class weights\n",
    "# -------------------------------\n",
    "classes = np.argmax(y, axis=1)\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(classes), y=classes)\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# -------------------------------\n",
    "# Callbacks\n",
    "# -------------------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"models/best_model.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# Train model\n",
    "# -------------------------------\n",
    "history = model.fit(\n",
    "    {\"skill_input\": X_train_s, \"numeric_input\": X_train_n},\n",
    "    y_train,\n",
    "    validation_data=({\"skill_input\": X_val_s, \"numeric_input\": X_val_n}, y_val),\n",
    "    class_weight=class_weight_dict,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97cdced2-050f-41ad-acec-6d93ff1297dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "Accuracy: 0.744\n",
      "Precision: 0.746\n",
      "Recall: 0.744\n",
      "F1 Score: 0.743\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Fit       1.00      1.00      1.00       176\n",
      "     Not Fit       0.60      0.68      0.64       176\n",
      " Partial Fit       0.63      0.55      0.59       176\n",
      "\n",
      "    accuracy                           0.74       528\n",
      "   macro avg       0.75      0.74      0.74       528\n",
      "weighted avg       0.75      0.74      0.74       528\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGJCAYAAADBveoRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7IklEQVR4nO3dB3gUVdvw8TuhhCKEGpJoqNKkiYARRAVBA0jUBywIKCqChSKJjwpKt2ADUaSIL0UfQRBF9AFFKdKkSDEqiBEQBCSA1FBDm++6z/vufrtJNoSws9ny/13XQKbs7JmzZe4959wzYZZlWQIAAGCjcDt3DgAAoAg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4EJIqV64sDz/8sHN+yZIlEhYWZv73Ft3f0KFDJRStXbtWmjVrJsWLFzf1kJKSYupC/86NUK27HTt2mGOfOnWq7c+lz6HPpc/p+rlo3769+IIdnzn4NwIO+Jzji84xFSlSRGrUqCG9e/eWffv2SSD5+uuv/fbEqCf5rl27SlxcnEREREiZMmWkdevWMmXKFDl//rxtz3v27Fm599575dChQ/L222/Lf/7zH6lUqZKEItf3ecGCBc1r0KhRI3n66aflt99+89rzjBs3zidBSrCVDb4Vxr1U4Gv65fPII4/I8OHDpUqVKnL69GlZsWKF88S0ceNGKVasmK1l0F9yLVq0cH4RXrhwQc6cOSOFCxeW8PDcx+EaJI0dO1ay+xjpcelJRidf+5//+R954oknpEKFCvLggw9K9erV5dixY7Jo0SKZN2+evPzyy/LCCy/Y8ty///671K5dWz744AN57LHHnMvPnTtnJg0wL0ZP0EOGDPHbYC639Dhuu+02eeihh8x75OjRo/Lzzz/LrFmz5MSJE/L6669LcnKyc3vdJiMjQwoVKiQFChTI9fPUrVtXypUrd0mtBRp0anCowaij5Uk/F7qvuXPnXuKRXnrZ8vqZQ+Dy/Tch8H/atm0rjRs3Nn/rials2bIyatQo+fLLL+WBBx7I9jH6Ja3N9N6mX3i5ORFeCm/vL7dWr15tgo2mTZuaFpgSJUo41/Xr10/WrVtngjq77N+/3/xfqlQpt+X5FXzlN22905YmV6+99pokJibKM888I7Vq1ZJ27dqZ5Y4WPzs5PkMa0FxKUBMInzn4N8JK+I1bb73V/L99+3bzv46xuOKKK2Tbtm3mC1lPnF26dHH+Oho9erTUqVPHfGnpL/nHH39cDh8+7LZP/cWov+avuuoq02rSsmVL2bRpU677k9esWWOeu3Tp0uZLun79+vLOO+84y6etG5mbznMah/DTTz+ZQKtkyZLm2Fq1amUChOy6nH744Qfz67d8+fLmuf/1r3/JP//8c9F6HDZsmHn8tGnT3IINBw3yXMev6AlIT3yOrpeaNWvKW2+9laXVRvepLTpz5swxv1p1W63/+fPnO7fR/d5yyy3mb+1W0cdoS5LKbgyH/ppPSkoyx6hlvfPOO2X37t3ZHtfff/8tjz76qHmtHc89efLkbF/HTz/9VF555RXzuuv7Q+t569atWfaZ0+vr2mJzzz33mO4Q3ZfW31dffSWXQ4PrGTNmmABMy5nTGI69e/eaFkE9Fj3umJgYueuuu5xjL7RVQt/TS5cudb4HHXXueC/puqeeekqioqLMfjyN4XD47rvv5NprrzXHe80118js2bPd1nsaj5N5nzmVzdNnTlt/tNupaNGipmVEgzV97V05vht0+d13323+1vfQv//9b1u7C3F5Qu/nBvyWBhaOL2MHbYJPSEiQ5s2bm5Ogo6tFgwtH10zfvn1NkPLee++ZE7qeqLVJWg0ePNgEHHpS0WnDhg1y++23m6bci1mwYIEZQKdf8NrnHh0dLZs3bzbNzTqvZdizZ4/ZTruDLka/eG+66SYTbDz33HOmjO+//775AtYv5Pj4eLft+/TpY06E2rWgX+AaYOkJf+bMmR6f4+TJk6bb5Oabb5aKFStetEwaVOhJ/vvvv5fu3bubk8y3334rzz77rPky1zEYrrTrS08+evLSAOHdd9+Vjh07ys6dO83rpnVy5ZVXyquvvmpelyZNmpgAwRNt2fr444+lc+fOZpDp4sWL5Y477siynY7tueGGG5xBj55cvvnmG1Pm9PR003KTuQVBf0HrCUi7Md544w0TrGqAkdvX1/Ga3XjjjeaY+vfvb4ISDWb0JPf555+bIDCv9PXR4EzrXo9B3xfZ0frVcuj7QU/g2oKkZdc613l9X+g6Pem++OKL5jGZ61xfL60z/TxogJmTLVu2yP33329aybp162bG/GjwqIGldg9dityUzZXjM63vmxEjRpjXXQNA/UzrZ9u11UwDC/1u0M+NfjcsXLhQRo4cKdWqVZMnn3zyksoJH9ExHIAvTZkyRX86WwsXLrT++ecfa9euXdaMGTOssmXLWkWLFrV2795ttuvWrZvZrn///m6PX758uVk+bdo0t+Xz5893W75//36rcOHC1h133GFduHDBud0LL7xgttP9O3z//fdmmf6vzp07Z1WpUsWqVKmSdfjwYbfncd1Xr169zOOyo8uHDBninL/77rtNebZt2+ZctmfPHqtEiRLWzTffnKV+Wrdu7fZcSUlJVoECBawjR454rNuff/7ZPPbpp5+2cmPOnDlm+5dfftlt+T333GOFhYVZW7dudTseLb/rMsfzjRkzJktdzpo1y22fWheudZWSkmLmn3rqKbftOnfunKXuunfvbsXExFgHDhxw27ZTp05WZGSkdfLkSbfnrl27tpWRkeHc7p133jHLf/3110t6fVu1amXVq1fPOn36tNv6Zs2aWdWrV8+xbh11pu8RT/R10m20HtX27dvNvL4HlJZN5998880cn6dOnTrWLbfckmW5473UvHlzc8zZrdPndND60GWff/65c9nRo0dN3Tds2NDja5nTPj2VLfNn7syZM1ZUVJRVt25d69SpU87t5s6da7YbPHiwc5nju2H48OFu+9QyNmrUKMe6Qv6hSwX5RjMm9FeXNuV36tTJ/Ar64osvzK9JV5l/rWiTa2RkpPm1deDAAeekzbC6D/3FqPQXj7Zk6C8s1+bfzL+Gs6O/prTVRLfNPBYht6mdrvTXmDZT6y/jqlWrOpfrr2v9da8tB/or11XPnj3dnktbR3Q/f/31l8fncewju66U7OgYD+3H19YIV9rFoudLbUXI/JrpL0gH7YLQX+Z//vlnrp4v83OrzM+d+fXRcmhrgo550L9dX3P9hastGNpy5Up/JetgRNe6U45y5ub11SwbbXG57777zIBbx3MePHjQPK+2BGRu6r9U+n5Vuv/saLeCHod2O2TuLrwUPXr0yPV4jdjYWLeWG319ddCr1pl279hFxxZp6422xriO7dAWLx3nooOdM9NWGFf6OuflvQjfoEsF+UbHP+iAOu3H1mZWHTuQebS6rnP0OTvoF72eZLQ/OqdBi44Ts2ZouNIgR7sqctO9o2MVvEHHXmh3hx5jZprRoWNSdu3aZcYlOGTuEnGUOacTj6NZ3tMJLDOtIz3BZA5QtEyO9a6y66bRcuXlZKj71tfbNYBRmetI6+7IkSMyceJEM+X0mue27nLz+uqYDw1wBg0aZCZPz5s5QL4Ux48fzzFA1DEbmsmiAaB+RrRbSbuBNADQLqDc0myw3Lr66quzBNX6OVXatXcpz3spHO+17D4jGnBoUO5KgxL9LHvjvQjfIOBAvrn++uudWSqe6Bdu5iBET84abOigyOxk/hIKVJ5+keaUya4nCw3Sfv31V78p0+XS11vp4EEdU5AdbWnxdjkdz6vjQLRFw1N9Xw7NFtKy5hQQaCuMtu7oYF0dX6PBj45v0NaXhg0b5up5tKXEmzy18vlywGZ+Ztggbwg4EHD0F7F2l+hgvpy+SB0Xm9IWEdduDP3FfLFfQY5f3XpC0G4ET3LbvaJBkA54TU1NzbJOsyA0qNKupculz6HZPnoy0haTi+1T60jrUltEXH9la5kc6+2i+9aTurY2uP6qzVxHjgwWPZnl9Fpcity8vo73jA7u9dbzutJBnzpYWNOXL9YFpuXVVg6d9P2sg3t1gKQOuM1rN9/FWnZc9/nHH3+Y/3WQqmuLkbY8uXZJZdfdl9uyOd5r+vo7MtYcdFmoXjwumDCGAwFH+9T15PPSSy9lWadZLfolqPQkoSeLMWPGuP2y1ZHzF3PdddeZX526rWN/Dq77clwTJPM22f0a0+wYvcaIaxqijsKfPn26ycLxlKVwqTSrRcuoF/xyNNm7Wr9+vXz44Yfmb83c0brUDB9Xmp2iJwpN4bWLY9+a6eIq8+ujdaeZGjqOI7vrh+QmVTgvr6+2omkGkWYSpaWleeV5HXR8iF5rRuvekb2RHe2G0wvIZQ4+NEDRlGLX9+HF3oO5pZlXOpbKdVzQRx99ZIIcR3eKI2BbtmyZczvNfnG8r1zltmza2ql1PmHCBLdj03FEmj2UXfYSAgstHAg4mkqo6ZfarKyX79YTuQYW+stPB5RqGp1eN8GRl6/bab+3nlx14Jt+gWl+f060xWH8+PGmKVu/aHUQog7w1F/+mqKoTdtKB6o6Bj5qs7ueHHUAbHY0PVfTGTW40IFx2vWhJzP9ctW0TW/R9FIdH6PPoX3frlca1cGHeg0JLYvS49Nrk+hJTwOhBg0amMGtGhhpU37m8RXepPWqJ1299LWOydFya0pvdtfL0DRXHQysKZA6AFKvDaEnbR0sqi00+velyO3rq/Wor1e9evXM82qrhwaJq1atMtcL0auGXoy2DmhLhAYyevJ2XGlUg0G90F2bNm1yfKxeQ0SDbD1mfc9oMKBlcH2f6ftQj0dfV+3m0RN35laC3NLxGppurPfD0XEjeq0TfT5Nj3XQz5yOk9HtNIVa3/e6nX7mtOXGVW7Lpp9hHa+ir4V+xvW94UiL1ZYVvV4LAlw+ZsggRDlS59auXZvjdpr6Vrx4cY/rJ06caFLgNJVWU0s1ffG5554zqaYO58+ft4YNG2bS+nS7Fi1aWBs3bjTpfzmlxTqsWLHCuu2228z+tSz169d3SwHVVMM+ffpY5cuXN2mkrh+pzKmdasOGDVZCQoJ1xRVXWMWKFbNatmxprVy5Mlf146mMnqxfv96kmMbGxlqFChWySpcubdI8P/zwQ1MvDseOHTMpt47tNN1T0zBd00NzSvH0VJcXS4tVmv7Yt29fkxKt9ZuYmGjSpLOru3379pnnj4uLM+WMjo42x6Pvg4s9d+Z009y+vkrTmB966CHzfPq8V155pdW+fXvrs88+y7H+HXXmmMLDw61SpUqZ1E1Nh920aVOW7TOXU9OA9Zhr1aplyqcpwPHx8dann37q9ri9e/ea9G89Dn28Iw01p8+ap7RY3c+3335r6iIiIsI8d+b6dLy/tCyaKl2xYkVr1KhR2e7TU9k8vZ9nzpxp6kifu0yZMlaXLl2cqfIX+27wlK4L/8C9VAAAgO0YwwEAAGxHwAEAAGxHwAEAAGxHwAEAAGxHwAEAAGxHwAEAAGzHhb/+754JenU9vXqfNy8RDABAsLMsy1xYUG8EmfneV64IOP7vUr7euI8FAAChateuXVnu7u2KgMPl1tBaWd66nwUAAKEgPT3d/Gi/2E0ICThc7maowQYBBwAAl+5iQxIYNAoAAGxHwAEAAGxHwAEAAGxHwAEAAGxHwAEAAGxHwAEAAGxHwAEAAGxHwAEAAGxHwAEAAII74Fi2bJkkJiaaG77oFcrmzJnjtl6XZTe9+eabzm0qV66cZf1rr72WD0cDAAD88tLmJ06ckAYNGsijjz4qHTp0yLI+LS3Nbf6bb76R7t27S8eOHd2WDx8+XHr06OGcv9j13AEA8Hc7d+6UAwcOeH2/5cqVk4oVK0pIBRxt27Y1kyfR0dFu819++aW0bNlSqlat6rZcA4zM2wIAEMjBRs1ateX0qZNe33eRosUk9ffNPg86Aubmbfv27ZN58+bJhx9+mGWddqG89NJLpvI6d+4sSUlJUrCg50PLyMgwk+ud7gAA8BcHDhwwwUbZ9s9IobJxXtvv2YO75ODckWb/BBweaKChLRmZu1769u0r1113nZQpU0ZWrlwpAwYMMF0xo0aN8rivESNGyLBhw3xQagAA8k6DjYjoqyUYBEzAMXnyZOnSpYsUKVLEbXlycrLz7/r160vhwoXl8ccfN0FFREREtvvSoMT1cdrCERfnvQgSAAAEYMCxfPlySU1NlZkzZ1502/j4eDl37pzs2LFDatasme02Goh4CkYAAECIXodj0qRJ0qhRI5PRcjEpKSkSHh4uUVFRPikbAADw8xaO48ePy9atW53z27dvNwGDjsdwDGbR7o5Zs2bJyJEjszx+1apVsmbNGpO5ouM7dF4HjHbt2lVKly7t02MBAAB+GnCsW7fOBAsOjnEV3bp1k6lTp5q/Z8yYIZZlyQMPPJDl8dotouuHDh1qsk6qVKliAg7X8RkAACDEA44WLVqYYCInPXv2NFN2NDtl9erVNpUOAACE1BgOAAAQ2Ag4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AABAcAccy5Ytk8TERImNjZWwsDCZM2eO2/qHH37YLHed2rRp47bNoUOHpEuXLlKyZEkpVaqUdO/eXY4fP+7jIwEAAH4bcJw4cUIaNGggY8eO9biNBhhpaWnO6ZNPPnFbr8HGpk2bZMGCBTJ37lwTxPTs2dMHpQcAALlVUPJR27ZtzZSTiIgIiY6Oznbd5s2bZf78+bJ27Vpp3LixWTZmzBhp166dvPXWW6blBAAA5D+/H8OxZMkSiYqKkpo1a8qTTz4pBw8edK5btWqV6UZxBBuqdevWEh4eLmvWrPG4z4yMDElPT3ebAABAiAYc2p3y0UcfyaJFi+T111+XpUuXmhaR8+fPm/V79+41wYirggULSpkyZcw6T0aMGCGRkZHOKS4uzvZjAQAglOVrl8rFdOrUyfl3vXr1pH79+lKtWjXT6tGqVas873fAgAGSnJzsnNcWDoIOAABCtIUjs6pVq0q5cuVk69atZl7Hduzfv99tm3PnzpnMFU/jPhzjQjSrxXUCAAD2CaiAY/fu3WYMR0xMjJlv2rSpHDlyRNavX+/cZvHixXLhwgWJj4/Px5ICAAC/6VLR62U4WivU9u3bJSUlxYzB0GnYsGHSsWNH01qxbds2ee655+Tqq6+WhIQEs33t2rXNOI8ePXrIhAkT5OzZs9K7d2/TFUOGCgAA/iNfWzjWrVsnDRs2NJPScRX69+DBg6VAgQLyyy+/yJ133ik1atQwF/Rq1KiRLF++3HSJOEybNk1q1aplxnRoOmzz5s1l4sSJ+XhUAADAr1o4WrRoIZZleVz/7bffXnQf2hIyffp0L5cMAACE7BgOAAAQmAg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AACA7Qg4AABAcAccy5Ytk8TERImNjZWwsDCZM2eOc93Zs2fl+eefl3r16knx4sXNNg899JDs2bPHbR+VK1c2j3WdXnvttXw4GgAA4JcBx4kTJ6RBgwYyduzYLOtOnjwpGzZskEGDBpn/Z8+eLampqXLnnXdm2Xb48OGSlpbmnPr06eOjIwAAALlRUPJR27ZtzZSdyMhIWbBggduy9957T66//nrZuXOnVKxY0bm8RIkSEh0dnevnzcjIMJNDenp6nsoPAACCcAzH0aNHTZdJqVKl3JZrF0rZsmWlYcOG8uabb8q5c+dy3M+IESNMQOOY4uLibC45AAChLV9bOC7F6dOnzZiOBx54QEqWLOlc3rdvX7nuuuukTJkysnLlShkwYIDpVhk1apTHfek2ycnJbi0cBB0AAIR4wKEDSO+77z6xLEvGjx/vts41cKhfv74ULlxYHn/8cdOKERERke3+dLmndQAAIAS7VBzBxl9//WXGdLi2bmQnPj7edKns2LHDZ2UEAAAB3MLhCDa2bNki33//vRmncTEpKSkSHh4uUVFRPikjAADw84Dj+PHjsnXrVuf89u3bTcCg4zFiYmLknnvuMSmxc+fOlfPnz8vevXvNdrpeu05WrVola9askZYtW5pMFZ1PSkqSrl27SunSpfPxyAAAgN8EHOvWrTPBQubxGN26dZOhQ4fKV199ZeavvfZat8dpa0eLFi3MOIwZM2aYbTXNtUqVKibgcB3XAQAAQjzg0KBBB4J6ktM6pdkpq1evtqFkAAAgpAaNAgCAwEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAAbEfAAQAA/DPgqFq1qhw8eDDL8iNHjph1AAAAlx1w7NixQ86fP59leUZGhvz999+53s+yZcskMTFRYmNjJSwsTObMmeO23rIsGTx4sMTExEjRokWldevWsmXLFrdtDh06JF26dJGSJUtKqVKlpHv37nL8+PG8HBYAALBJwUvZ+KuvvnL+/e2330pkZKRzXgOQRYsWSeXKlXO9vxMnTkiDBg3k0UcflQ4dOmRZ/8Ybb8i7774rH374oVSpUkUGDRokCQkJ8ttvv0mRIkXMNhpspKWlyYIFC+Ts2bPyyCOPSM+ePWX69OmXcmgAAMBfAo67777b/K+tEd26dXNbV6hQIRNsjBw5Mtf7a9u2rZmyo60bo0ePloEDB8pdd91lln300UdSoUIF0xLSqVMn2bx5s8yfP1/Wrl0rjRs3NtuMGTNG2rVrJ2+99ZZpOQEAAAHWpXLhwgUzVaxYUfbv3++c10m7U1JTU6V9+/ZeKdj27dtl7969phvFQVtU4uPjZdWqVWZe/9duFEewoXT78PBwWbNmjcd9a1nT09PdJgAA4GdjODQYKFeunNhJgw2lLRqudN6xTv+PiopyW1+wYEEpU6aMc5vsjBgxwgQvjikuLs6WYwAAAHnoUnGl4zV0crR0uJo8ebL4swEDBkhycrJzXls4CDoAAPCzgGPYsGEyfPhw05WhGSQ6psPboqOjzf/79u0zz+Gg89dee61zGw14XJ07d85krjgen52IiAgzAQAAPw44JkyYIFOnTpUHH3xQ7KJZKRo0aCuKI8DQlggdm/Hkk0+a+aZNm5prf6xfv14aNWpkli1evNi0uOhYDwAAEMABx5kzZ6RZs2aX/eR6vYytW7e6jQ1JSUkxYzB0YGq/fv3k5ZdflurVqzvTYjXzxJEtU7t2bWnTpo306NHDBEGaFtu7d2+TwUKGCgAAAT5o9LHHHvPKdS7WrVsnDRs2NJPScRX6t17sSz333HPSp08fc12NJk2amABF02Ad1+BQ06ZNk1q1akmrVq1MOmzz5s1l4sSJl102AACQzy0cp0+fNif1hQsXSv369c01OFyNGjUqV/tp0aKFud6GJzo2RMeK6OSJtoZwkS8AAIIw4Pjll1+c4yo2btzots6OAaQAACAEA47vv//e+yUBAABBi9vTAwAA/2zhaNmyZY5dJ5qaCgAAcFkBh2P8hoOmo2o6q47nyHxTNwAAgDwFHG+//Xa2y4cOHWpSVwEAAGwbw9G1a1e/v48KAAAI8IBDbxfvelEuAACAPHepdOjQwW1eL96VlpZmrhyqlx8HAAC47IAjMjLSbT48PFxq1qxprgh6++2352WXAAAgiOUp4JgyZYr3SwIAAIJWngIOB70t/ObNm83fderUcd6EDQAA4LIDjv3795tbwC9ZskRKlSpllh05csRcEGzGjBlSvnz5vOwWAAAEqTxlqegt448dOyabNm2SQ4cOmUkv+pWeni59+/b1fikBAEDotXDMnz/f3Jq+du3azmXXXHONjB07lkGjAADAOy0cFy5ckEKFCmVZrst0HQAAwGUHHLfeeqs8/fTTsmfPHueyv//+W5KSkqRVq1Z52SUAAAhieQo43nvvPTNeo3LlylKtWjUzValSxSwbM2aM90sJAABCbwxHXFycbNiwwYzj+P33380yHc/RunVrb5cPAACEWgvH4sWLzeBQbckICwuT2267zWSs6NSkSRNzLY7ly5fbV1oAABD8Acfo0aOlR48eUrJkyWwvd/7444/LqFGjvFk+AAAQagHHzz//LG3atPG4XlNi9eqjAAAAeQ449u3bl206rEPBggXln3/+uZRdAgCAEHBJAceVV15prijqyS+//CIxMTHeKBcAAAjVgKNdu3YyaNAgOX36dJZ1p06dkiFDhkj79u29WT4AABBqabEDBw6U2bNnS40aNaR3795Ss2ZNs1xTY/Wy5ufPn5cXX3zRrrICAIBQCDgqVKggK1eulCeffFIGDBgglmWZ5Zoim5CQYIIO3QYAAOCyLvxVqVIl+frrr+Xw4cOydetWE3RUr15dSpcufam7AgAAISJPVxpVGmDoxb4AAABsuZcKAADApSDgAAAAtvP7gEPvSKuDUjNPvXr1MutbtGiRZd0TTzyR38UGAADeGMPhK2vXrjXptg564TG9ady9997rXKb3dxk+fLhzvlixYj4vJwAACOCAo3z58m7zr732mlSrVk1uueUWtwAjOjo6H0oHAACCokvF1ZkzZ+Tjjz+WRx991HSdOEybNk3KlSsndevWNdcHOXnyZI77ycjIkPT0dLcJAACEcAuHqzlz5siRI0fk4Ycfdi7r3LmzuTZIbGysuZfL888/L6mpqeaKqJ6MGDFChg0b5qNSAwCAgAo4Jk2aJG3btjXBhUPPnj2df9erV8/cPK5Vq1aybds20/WSHW0FSU5Ods5rC0dcXJzNpQcAIHQFTMDx119/ycKFC3NsuVDx8fHmf70KqqeAIyIiwkwAAMA3AmYMx5QpUyQqKkruuOOOHLdLSUkx/2tLBwAA8A8B0cJx4cIFE3B069ZNChb8/0XWbpPp06dLu3btpGzZsmYMR1JSktx8881Sv379fC0zAAAIsIBDu1J27txpslNcFS5c2KwbPXq0nDhxwozD6NixowwcODDfygoAAAI04Lj99tvNXWkz0wBj6dKl+VImAAAQhGM4AABA4CLgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAtiPgAAAAoR1wDB06VMLCwtymWrVqOdefPn1aevXqJWXLlpUrrrhCOnbsKPv27cvXMgMAgAALOFSdOnUkLS3NOa1YscK5LikpSf773//KrFmzZOnSpbJnzx7p0KFDvpYXAABkVVD8XMGCBSU6OjrL8qNHj8qkSZNk+vTpcuutt5plU6ZMkdq1a8vq1avlhhtuyIfSAgCAgGzh2LJli8TGxkrVqlWlS5cusnPnTrN8/fr1cvbsWWndurVzW+1uqVixoqxatSrHfWZkZEh6errbBAAAQjTgiI+Pl6lTp8r8+fNl/Pjxsn37drnpppvk2LFjsnfvXilcuLCUKlXK7TEVKlQw63IyYsQIiYyMdE5xcXE2HwkAAKHNr7tU2rZt6/y7fv36JgCpVKmSfPrpp1K0aNE873fAgAGSnJzsnNcWDoIOAABCtIUjM23NqFGjhmzdutWM6zhz5owcOXLEbRvNUsluzIeriIgIKVmypNsEAADsE1ABx/Hjx2Xbtm0SExMjjRo1kkKFCsmiRYuc61NTU80Yj6ZNm+ZrOQEAQAB1qfz73/+WxMRE042iKa9DhgyRAgUKyAMPPGDGXnTv3t10jZQpU8a0UvTp08cEG2SoAADgX/w64Ni9e7cJLg4ePCjly5eX5s2bm5RX/Vu9/fbbEh4ebi74pZknCQkJMm7cuPwuNgAACKSAY8aMGTmuL1KkiIwdO9ZMAADAfwXUGA4AABCYCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCDgAAIDtCtr/FAhFO3fulAMHDnh1n+XKlZOKFSt6dZ8AAN8g4LBRqJ509bhr1qotp0+d9Op+ixQtJqm/b/b74wcAZEXAYZNQPulqkKXHXbb9M1KobJxX9nn24C45OHek2bc/HzsAIHsEHDbhpCvmuCOir87vYgAA/AABh8046QIA4OcBx4gRI2T27Nny+++/S9GiRaVZs2by+uuvS82aNZ3btGjRQpYuXer2uMcff1wmTJggwWrz5s1e3V9GRoZERET4bflgn1AdZwTA9/w64NBAolevXtKkSRM5d+6cvPDCC3L77bfLb7/9JsWLF3du16NHDxk+fLhzvlixYhKMzh8/LBIWJl27dvXujsPCRawLEorsOOEGykk3lMcZAfA9vw445s+f7zY/depUiYqKkvXr18vNN9/sFmBER0dLsLuQcVzEsrw6LuTUn+vk6PKPbdmnv7PrhBsoJ13GGQHwJb8OODI7evSo+b9MmTJuy6dNmyYff/yxCToSExNl0KBBObZyaBeCTg7p6ekSquNC9ARh1z79nR0nXDtPut5ujXF0fTHOCIAvBEzAceHCBenXr5/ceOONUrduXefyzp07S6VKlSQ2NlZ++eUXef755yU1NdWM/chpbMiwYcN8VHL4u0A44drZGgMAvhAwAYeO5di4caOsWLHCbXnPnj2df9erV09iYmKkVatWsm3bNqlWrVq2+xowYIAkJye7tXDExXnvFy4QCK0xgdL1BSA4BETA0bt3b5k7d64sW7ZMrrrqqhy3jY+PN/9v3brVY8ChGRnezMqA73gzAyYQs2lCsesLQHDw64DDsizp06ePfPHFF7JkyRKpUqXKRR+TkpJi/teWDgQP2zJ0AAA+UdDfu1GmT58uX375pZQoUUL27t1rlkdGRprrcmi3ia5v166dlC1b1ozhSEpKMhks9evXz+/iI0AydOB93m49CoQ0YwABHHCMHz/eeXEvV1OmTJGHH35YChcuLAsXLpTRo0fLiRMnzDiMjh07ysCBA/OpxLAbXQqh2RIVCGnGAAK8SyUnGmBkvsoogOBqiQqUNGNFSwwQoAEHgMDk76nGXGUV8D0CDgAhh6usAr5HwAEgZPl7SwwQTMLzuwAAACD4EXAAAADb0aUCICAEylVm7dg32S8IBgQcAPxaoFxl1s5ykv2CYEDAAcCvBcpVZu0opyL7BcGCgANAQAiUq8yS+QJkj0GjAADAdgQcAADAdgQcAADAdozhAEI8jROBwdvvgYyMDImIiPDqPknfRU4IOIAQTeNEiL+fwsJFrAte3SXpu8gJAQcQommcCAx2vp+4eR18iYADCPE0ToTu+4kUXvgSg0YBAIDtCDgAAIDtCDgAAIDtGMMBAPDb9F1SbYMHAQcAwG/Td0m1DR4EHAAAv0zfJdU2uBBwAAC8hlRbeMKgUQAAYDtaOAAAfo2BqMGBgAMAEFIDUSMiisjnn38mMTExXtsnQczFEXAAAEJmIOrp3ZvkyOL/kfbt24s3kU1zcQQcAIDQuo8M2TT5goADABByyKbxPbJUAACA7WjhAADAz7JpNns5M8cfBE3AMXbsWHnzzTdl79690qBBAxkzZoxcf/31+V0sAECQsyubJtgERcAxc+ZMSU5OlgkTJkh8fLyMHj1aEhISJDU1VaKiovK7eACAIGZHNs2pP9fJ0eUfSzAJioBj1KhR0qNHD3nkkUfMvAYe8+bNk8mTJ0v//v3zu3gAgBDg9WyaIBPwAceZM2dk/fr1MmDAAOey8PBwad26taxatSrbx2RkZJjJ4ejRo+b/9PR0r5Xr+PHj//tce7fKhTOnvfoGZJ/+u0+79ss+Q3Ofdu2XfYbmPtXZQ7ud5yhvnfMc+7EsK+cNrQD3999/6xFaK1eudFv+7LPPWtdff322jxkyZIh5DBMTExMTE5N4Zdq1a1eO5+uAb+HIC20N0TEfDhcuXJBDhw5J2bJlJSwszGsRX1xcnOzatUtKlizplX2GMurT+6hT76I+vY86DYw61ZaNY8eOSWxsbI7bBXzAodevL1CggOzbt89tuc5HR0dn+5iIiAgzuSpVqpQt5dMXlA+K91Cf3kedehf16X3Uqf/XaWRkZPBf+Ktw4cLSqFEjWbRokVuLhc43bdo0X8sGAACCpIVDafdIt27dpHHjxubaG5oWe+LECWfWCgAAyF9BEXDcf//98s8//8jgwYPNhb+uvfZamT9/vlSoUCHfyqRdNkOGDMnSdYO8oT69jzr1LurT+6jT4KrTMB056vNnBQAAISXgx3AAAAD/R8ABAABsR8ABAABsR8ABAABsR8BxGcaOHSuVK1eWIkWKmLvU/vjjjx63nTp1qrmKqeukj0Pe6lMdOXJEevXqJTExMWbEdY0aNeTrr7/2WXmDrU5btGiR5T2q0x133OHTMgfTe1RT9GvWrClFixY1V3dMSkqS06e9d1+MUKvTs2fPyvDhw6VatWpm+wYNGpiMRPyvZcuWSWJiornip35258yZIxezZMkSue6668x36NVXX23OVbbx5n1NQsmMGTOswoULW5MnT7Y2bdpk9ejRwypVqpS1b9++bLefMmWKVbJkSSstLc057d271+flDpb6zMjIsBo3bmy1a9fOWrFihbV9+3ZryZIlVkpKis/LHix1evDgQbf358aNG60CBQqY9y4uvT6nTZtmRUREmP/1/fntt99aMTExVlJSks/LHix1+txzz1mxsbHWvHnzrG3btlnjxo2zihQpYm3YsMHnZfdHX3/9tfXiiy9as2fPNvc2+eKLL3Lc/s8//7SKFStmJScnW7/99ps1ZswY85mfP3++LeUj4MgjvTFcr169nPPnz583H4QRI0Zku71+aUdGRvqwhMFdn+PHj7eqVq1qnTlzxoelDO46zeztt9+2SpQoYR0/ftzGUgZvfeq2t956q9sy/WK/8cYbbS9rsNapBmzvvfee27IOHTpYXbp0sb2sgUZyEXBoAFenTh23Zffff7+VkJBgS5noUsmDM2fOyPr166V169bOZeHh4WZ+1apVHh+ntwOuVKmSaVq96667ZNOmTT4qcfDV51dffWUuXa9dKnqBt7p168qrr74q58+f92HJg+896mrSpEnSqVMnKV68uIS6vNRns2bNzGMcXQR//vmn6fJr166dz8odbHWakZGRpStau6tWrFhhe3mD0apVq9zqXyUkJOT6O+JSEXDkwYEDB8yJLfOVTHVer3SaHe3HnTx5snz55Zfy8ccfm/u96BfS7t27JdTlpT71y/uzzz4zj9Mv8UGDBsnIkSPl5Zdf9lGpg69OXelJcuPGjfLYY4/ZWMrgrs/OnTub8QbNmzeXQoUKmXEHOk7mhRde8FGpg69O9WQ4atQo2bJli/kOXbBggcyePVvS0tJ8VOrgsnfv3mzrX+8oe+rUKa8/HwGHj+iv8Yceeshcdv2WW24xH5Ly5cvL+++/n99FC0j6ZRMVFSUTJ040N+/Ty9u/+OKLMmHChPwuWlDQ1o169eqZexMhb3Qwnra6jRs3TjZs2GA+8/PmzZOXXnopv4sWsN555x2pXr261KpVy9y4s3fv3uaeWdoyAv8XFPdS8bVy5cpJgQIFZN++fW7LdT46OjpX+9BfPA0bNpStW7dKqMtLfWpmitahPs6hdu3aJmLXplr9Mgpll/Me1Rsfzpgxw/w6R97rU1vdHnzwQWcrkQZwWrc9e/Y0wXGonyTzUqf6I00zLzTT5+DBgyYbo3///lK1alUflTq4REdHZ1v/ett67aryttB+x+eRnsz0V/WiRYvcfnHrvLZk5IY2Jf7666/mxBnq8lKfN954ownWdDuHP/74w9RnqAcbl/senTVrlukr79q1qw9KGrz1efLkySxBhSNA5hZWl/ce1XEcV155pZw7d04+//xzMyYOl07r2bX+lXZT5fY8dslsGYoaIulcmvI2depUk07Us2dPk87lSHV98MEHrf79+zu3HzZsmEmL01Su9evXW506dTLpXJoKhkuvz507d5oMit69e1upqanW3LlzraioKOvll1/Ox6MI7Dp1aN68uRmpjsurzyFDhpj36CeffGLSD7/77jurWrVq1n333ZePRxHYdbp69Wrr888/N9+jy5YtM1lAVapUsQ4fPpyPR+E/jh07Zv30009m0tP7qFGjzN9//fWXWa91qXWaOS322WeftTZv3myNHTuWtFh/pTnLFStWNHnkmt6lHwaHW265xerWrZtzvl+/fs5tK1SoYK4fQe543utTrVy50oqPjzdfWJoi+8orr1jnzp3Lh5IHT53+/vvv5otKT464vPo8e/asNXToUBNk6I+LuLg466mnnuLkeBl1qtfaqV27tvnMly1b1pw8//7773wquf/5/vvvzec38+SoQ/1f6zTzY6699lpT//o9aud1d7g9PQAAsB1jOAAAgO0IOAAAgO0IOAAAgO0IOAAAgO0IOAAAgO0IOAAAgO0IOAAAgO0IOAAAgO0IOAB4pPcD6dixo7mZU1hYmBw5ckRCmdaB3jzscgwdOtTcNTonDz/8sNx9993Oeb2tfb9+/ZzzlStXltGjR19WOQBfI+AAbKInDT1BPfHEE1nW9erVy6zTbfzZhx9+KMuXL5eVK1dKWlqaHD582JQ7JSUlv4sW9Ldhnzp1qsf1a9euNXed9WYgBNiNgAOwUVxcnLnV+6lTp5zL9Nba06dPl4oVK4q/27Ztm9SuXVvq1q1rbmWtJ7ZgdPbsWfEnkZGRUqpUKY/r9TbtxYoV82mZgMtFwAHY6LrrrjNBx+zZs53L9G8NNho2bOi27fz586V58+bmRFO2bFlp3769OeE7fPTRR3LFFVfIli1bnMueeuopqVWrlun6yM7PP/8sLVu2lBIlSphuEb0d+Lp165zr9dbederUkYiICNNMP3LkSLdmfJ1ftmyZCTR0vkqVKmadlt2xzLUL4NVXX5UKFSqYYxg+fLi5ffizzz4rZcqUkauuukqmTJniVr7nn39eatSoYU6eVatWlUGDBjlP/nqbp9atW0tCQoLzdu6HDh0y+xk8eLDHOtfjeOmll+SBBx6Q4sWLm9uYjx071m0bLfv48ePlzjvvNNu88sorZrkuq1atmrl1es2aNeU///lPlv1rS0/btm2laNGipsyfffZZro/J1fvvv2/eG7rdfffdJ0ePHvXYpZLdMTq6VPRv9a9//cscl87v2LFDwsPD3V5rpY+pVKmSuQ084HO23RYOCHF6Z8a77rrL3CK6VatWzuX699tvv23Wud4J87PPPjO33t6yZYu5pXRiYqJVr1496/z5885t7r33XqtJkybmTqRz5861ChUqZK1bt85jGerUqWN17drV3Hr6jz/+sD799FMrJSXFrNPHhYeHW8OHD7dSU1PNXSKLFi3qvFvkwYMHrR49elhNmza10tLSzPyPP/5o7j65cOFC5zLHseqt2Hv16mXuODtp0iSzXUJCgrmLrz73Sy+9ZMq7a9cuZ/l02Q8//GBt377d+uqrr8ydlF9//XXn+t27d1ulS5e2Ro8e7Tx+vaOoHr8nlSpVMmUZMWKEOa53333X3HLb9Q64WraoqChr8uTJ5lbnevvu2bNnm/LpLbr1cSNHjjSPW7x4sdvj9C6lH3zwgdlm4MCBZhu9tXpuj0lvW1+8eHFza3V9nZcuXWpdffXVVufOnbO8dxz0Dp9PP/202zHqe0jt37/flEtfN31NdF7ddttt5u60rurXr28NHjzYY90BdiLgAGziOGnoCUBvp71jxw4z6a3K//nnnywBR2a6jZ5Ifv31V+eyQ4cOWVdddZX15JNPmhOZnsxzoifeqVOnZrtOT3B6UnL17LPPWtdcc41zXk9yrrez1pOolklPlJmPVU+CrsFRzZo1rZtuusk5f+7cOXOi/eSTTzyW980337QaNWrktkyDJK2z/v37m8dr8JITLUebNm3clt1///1W27ZtnfN6DP369XPbplmzZibAcqUBTrt27dwe98QTT7htEx8fb16P3B6TBhwapGgw5fDNN9+Y4E8DhksNOBzl+uKLL9yed+bMmSZYO336tJlfv369FRYWZl5DID/QpQLYTPvb77jjDjMIULsU9O9y5cpl2U67SrQbQJvhtfvD0VS+c+dO5zalS5eWSZMmOZv++/fvn+NzJycny2OPPWa6Jl577TW3LprNmzfLjTfe6La9zms5zp8/f8nHqV0z2ozvoF0r9erVc84XKFDAdBXt37/fuWzmzJnmOXV8iHYXDRw40O141b333mu6C7T8b731llSvXv2iZWnatGmWeT1eV40bN3ab91QfmR93sX3n5pi0S027elz3od0cqamp4i3aJaN1/sUXX5h5ff9p95rjfQX4GgEH4AOPPvqo+cLXrA/9OzuJiYlmjMIHH3wga9asMZM6c+aM23Y6pkJPJDqW4MSJExdNwdy0aZMJchYvXizXXHON8wTkbYUKFXKb1/EE2S1zjB9YtWqVdOnSRdq1aydz586Vn376SV588cUsx6vjU9avX2+O2XX8yuXSsRvelttj8gUdh/LQQw+ZIFefXwcqe3rvAb5AwAH4QJs2bcyXvg4e1EGQmR08eND8utVfw61atTKZIZqCmpmmp77++uvy3//+1/x67t2790WfWwcwJiUlyXfffScdOnRwDtzU5/jhhx/cttV53V5P7p5OYiovLSDZHYsOYNQTsrY2aMvFX3/9lWW7Z555xrScfPPNN/Luu++awOliVq9enWVejzcnnupDg7Tc7ju3x6QtHnv27HHbhx6jDlTNCw3ssntNtHVr4cKFMm7cODOAV19/IL8UzLdnBkKInsAdze7Zncy1q0S7GyZOnCgxMTHmhJS5u+TYsWPy4IMPSt++fU2WhGZrNGnSxLSM3HPPPVn2qam4miGi6zS7ZPfu3eb6DXohL8eJXB+vGR3333+/+XX+3nvvmZOTJ1FRUSY7QzNq9PmLFCliUjjzQk/GepyaNqzlmDdvXpbWF102efJkUzbN+NHj6datm/zyyy+mzjzRQOGNN94w3QoLFiyQWbNmmX3lRPet2SKagaNdUBrUaUaRnrBd6b40mNCMomnTpsmPP/5ourlye0xK602PQ7uI0tPTzWuqz63dMHmh3SSLFi0yXTmaceSoGw2EbrjhBpM5o60b+toB+SZfRo4AISDzwL/MMg8aXbBggVW7dm0zwFSzCZYsWeI2GPCRRx4xWSuOQYBKMynKlCnjNgDRISMjw+rUqZMVFxdnFS5c2IqNjbV69+5tnTp1yi0zRgeJanZGxYoVzQBHV5kHjSrN0NB96iBHx7rsjjXzQMfsBjvqIFXN+rjiiivMwE5dFxkZadbpYFsdGPvqq686tz9z5owZgHnfffd5rFd9jmHDhpkBn8WKFbOio6Otd955x22b7AZZqnHjxllVq1Y19VGjRg3ro48+yvI4zWLRwbb6OlWuXNkMznSV0zE5Bo02aNDAPJe+Jjog9p577jEDgh0uddCoZsNopkvBggXNOleOjCHNMALyU5j+k3/hDgB4l/7a18uAu14KPJRpC5a2ymirEJCfGMMBAEHo+PHjsnHjRtNN1qdPn/wuDkDAAQDBSAcU65Vl9WqwZKfAH9ClAgAAbEcLBwAAsB0BBwAAsB0BBwAAsB0BBwAAsB0BBwAAsB0BBwAAsB0BBwAAsB0BBwAAELv9P5/EoZK2csGtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 7 â€” Metrics & Evaluation\n",
    "# ================================\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_probs = model.predict({\"skill_input\": X_test_s, \"numeric_input\": X_test_n})\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Accuracy, Precision, Recall, F1\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"\\n=== Evaluation Metrics ===\")\n",
    "print(\"Accuracy:\", round(acc, 3))\n",
    "print(\"Precision:\", round(precision, 3))\n",
    "print(\"Recall:\", round(recall, 3))\n",
    "print(\"F1 Score:\", round(f1, 3))\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Calibration: predicted probability histogram\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(np.max(y_pred_probs, axis=1), bins=20, edgecolor=\"k\")\n",
    "plt.title(\"Prediction Confidence Distribution\")\n",
    "plt.xlabel(\"Max softmax probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0de51e4-265c-427c-a28e-1951f504033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Rule-based explanation (short) ---\n",
      "\n",
      "Predicted label: Not Fit (model confidence: 0.61) Raw test score: 54 / 100 (normalized: 0.54) Skill match: 0 / 7 â†’ ratio\n",
      "0.00 Projects: 2; Years experience (sum): 5.0 Top missing required skills: AWS, Kubernetes, Terraform Recommendations:\n",
      "Add containerization (Docker) example or CI/CD step.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 8 â€” Interpretability & Explanation\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "import textwrap\n",
    "\n",
    "# Helper: build flat vector used by model (same logic as Step 4)\n",
    "def build_flat_vector_for_model(resume, skill_index, project_scaler, years_scaler, use_embeddings=False):\n",
    "    # skill binary\n",
    "    skill_vec = encode_skills(resume[\"skills\"], skill_index)\n",
    "    # matched ratio\n",
    "    _, _, ratio = matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])\n",
    "    # append ratio to skill vector (as used earlier)\n",
    "    skill_features = np.append(skill_vec, ratio).astype(float)\n",
    "    # numeric vector (test_score_norm, project_scaled, years_scaled, ratio)\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    project_scaled, years_scaled = transform_numeric_features(resume, project_scaler, years_scaler)\n",
    "    test_score_norm = normalize_test_score(resume[\"test_score\"])\n",
    "    numeric_vector = np.array([test_score_norm, project_scaled, years_scaled, ratio], dtype=float)\n",
    "    # final concatenation (no text embeddings here; if you used embeddings in training, extend accordingly)\n",
    "    final = np.concatenate([skill_features, numeric_vector])\n",
    "    return final, skill_features, numeric_vector, ratio\n",
    "\n",
    "# Prediction wrapper: accepts single flat vector and returns softmax probs\n",
    "def predict_from_flat_vector(flat_vec):\n",
    "    # split back into inputs expected by the Keras model\n",
    "    V_plus_ratio = len(skill_vocab) + 1  # same as during training: skill_vocab + ratio\n",
    "    skill_input = flat_vec[:V_plus_ratio].reshape(1, -1)\n",
    "    numeric_input = flat_vec[V_plus_ratio:V_plus_ratio + 4].reshape(1, -1)\n",
    "    preds = model.predict({\"skill_input\": skill_input, \"numeric_input\": numeric_input}, verbose=0)\n",
    "    return preds.flatten()\n",
    "\n",
    "# Rule-based explanation template generator\n",
    "def rule_based_explanation(resume, prob, label):\n",
    "    matched, missing, ratio = matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    raw_score = resume.get(\"test_score\", None)\n",
    "    score_norm = normalize_test_score(raw_score) if raw_score is not None else None\n",
    "    top_missing = missing[:3] if missing else []\n",
    "    \n",
    "    lines = []\n",
    "    lines.append(f\"Predicted label: {label} (model confidence: {prob:.2f})\")\n",
    "    lines.append(f\"Raw test score: {raw_score} / 100 (normalized: {score_norm:.2f})\")\n",
    "    lines.append(f\"Skill match: {len(matched)} / {len(domain_requirements[resume['preferred_domain']]['required_skills'])} â†’ ratio {ratio:.2f}\")\n",
    "    lines.append(f\"Projects: {project_count}; Years experience (sum): {years_exp}\")\n",
    "    if top_missing:\n",
    "        lines.append(\"Top missing required skills: \" + \", \".join(top_missing))\n",
    "    else:\n",
    "        lines.append(\"No missing required skills (meets all listed domain requirements).\")\n",
    "    \n",
    "    # Add quick recommendation\n",
    "    recs = []\n",
    "    if label != \"Fit\":\n",
    "        if \"PyTorch\" in top_missing or \"Deep Learning\" in top_missing:\n",
    "            recs.append(\"Add a Deep Learning project (PyTorch/TensorFlow).\")\n",
    "        if \"Docker\" in top_missing or \"Kubernetes\" in top_missing:\n",
    "            recs.append(\"Add containerization (Docker) example or CI/CD step.\")\n",
    "        if len(resume.get(\"projects\", [])) == 0:\n",
    "            recs.append(\"Add at least one hands-on project demonstrating key skills.\")\n",
    "    if not recs:\n",
    "        lines.append(\"Recommendation: Keep profile and add more high-impact projects to increase confidence.\")\n",
    "    else:\n",
    "        lines.append(\"Recommendations: \" + \" \".join(recs))\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Optional: SHAP attribution (if shap installed). We use KernelExplainer on a small background subset.\n",
    "def shap_explain(resume_flat, background_flat_array, feature_names=None, nsamples=100):\n",
    "    try:\n",
    "        import shap\n",
    "    except Exception as e:\n",
    "        print(\"SHAP not available:\", e)\n",
    "        return None\n",
    "    \n",
    "    # function that maps a 2D array of flat vectors -> model probabilities for each class (returns shape n x 3)\n",
    "    def f(X):\n",
    "        preds = []\n",
    "        for row in X:\n",
    "            preds.append(predict_from_flat_vector(row))\n",
    "        return np.vstack(preds)\n",
    "    \n",
    "    explainer = shap.KernelExplainer(f, background_flat_array, link=\"identity\")\n",
    "    # explain original instance\n",
    "    shap_values = explainer.shap_values(resume_flat, nsamples=nsamples)\n",
    "    # shap_values is list length n_classes; each is array (1, n_features)\n",
    "    return shap_values\n",
    "\n",
    "# Sensitivity test: perturb test_score by +/- 10% and observe label/confidence changes\n",
    "def sensitivity_test(resume, skill_index, project_scaler, years_scaler):\n",
    "    base_flat, skill_features, numeric_vector, ratio = build_flat_vector_for_model(resume, skill_index, project_scaler, years_scaler)\n",
    "    base_probs = predict_from_flat_vector(base_flat)\n",
    "    base_label = label_encoder.inverse_transform([np.argmax(base_probs)])[0]\n",
    "    # prepare perturbed resume copies\n",
    "    perturbed_results = {}\n",
    "    for pct in [-0.1, 0.1]:\n",
    "        new_resume = dict(resume)  # shallow copy\n",
    "        new_score = int(np.clip(resume.get(\"test_score\",0) * (1 + pct), 0, 100))\n",
    "        new_resume[\"test_score\"] = new_score\n",
    "        pert_flat, _, _, _ = build_flat_vector_for_model(new_resume, skill_index, project_scaler, years_scaler)\n",
    "        probs = predict_from_flat_vector(pert_flat)\n",
    "        label = label_encoder.inverse_transform([np.argmax(probs)])[0]\n",
    "        perturbed_results[f\"{int(pct*100)}%\"] = {\"test_score\": new_score, \"label\": label, \"confidence\": float(np.max(probs))}\n",
    "    return {\n",
    "        \"base\": {\"test_score\": int(resume.get(\"test_score\",0)), \"label\": base_label, \"confidence\": float(np.max(base_probs))},\n",
    "        \"perturbations\": perturbed_results\n",
    "    }\n",
    "\n",
    "# Main explanation function combining everything\n",
    "def explain_resume(resume, skill_index, project_scaler, years_scaler, background_resumes_for_shap=None, shap_nsamples=100, use_shap=False):\n",
    "    # Build flat\n",
    "    flat, _, _, _ = build_flat_vector_for_model(resume, skill_index, project_scaler, years_scaler)\n",
    "    probs = predict_from_flat_vector(flat)\n",
    "    pred_idx = int(np.argmax(probs))\n",
    "    pred_label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "    pred_conf = float(np.max(probs))\n",
    "    \n",
    "    # Rule-based explanation\n",
    "    rule_text = rule_based_explanation(resume, pred_conf, pred_label)\n",
    "    \n",
    "    # SHAP (optional)\n",
    "    shap_result = None\n",
    "    if use_shap:\n",
    "        if background_resumes_for_shap is None:\n",
    "            print(\"No background provided for SHAP; skipping SHAP.\")\n",
    "        else:\n",
    "            # build background flat array (take up to 50)\n",
    "            bg_flats = []\n",
    "            for r in background_resumes_for_shap[:50]:\n",
    "                bf, _, _, _ = build_flat_vector_for_model(r, skill_index, project_scaler, years_scaler)\n",
    "                bg_flats.append(bf)\n",
    "            bg_arr = np.vstack(bg_flats)\n",
    "            sv = shap_explain(flat, bg_arr, nsamples=shap_nsamples)\n",
    "            if sv is not None:\n",
    "                # format top positive/negative contributors for predicted class\n",
    "                class_shap = sv[pred_idx].flatten()  # shape (n_features,)\n",
    "                # pair feature names: first V features are skill names + 'skill_match_ratio', then numeric features\n",
    "                feat_names = skill_vocab + [\"skill_match_ratio\", \"test_score_norm\", \"project_count_scaled\", \"years_experience_scaled\", \"skill_match_ratio_dup\"]\n",
    "                # Note: because we concatenated skill_features then numeric_vector, ensure names align; adjust if necessary.\n",
    "                # We'll create simple top-K summary:\n",
    "                top_k = 6\n",
    "                idx_sorted = np.argsort(-np.abs(class_shap))[:top_k]\n",
    "                contribs = []\n",
    "                for i in idx_sorted:\n",
    "                    name = feat_names[i] if i < len(feat_names) else f\"f_{i}\"\n",
    "                    contribs.append((name, float(class_shap[i])))\n",
    "                shap_result = contribs\n",
    "    \n",
    "    # Sensitivity\n",
    "    sensitivity = sensitivity_test(resume, skill_index, project_scaler, years_scaler)\n",
    "    borderline_flag = False\n",
    "    if abs(sensitivity[\"base\"][\"confidence\"] - np.max([v[\"confidence\"] for v in sensitivity[\"perturbations\"].values()])) > 0.2:\n",
    "        borderline_flag = True\n",
    "    \n",
    "    # Compose final JSON-like explanation\n",
    "    explanation = {\n",
    "        \"id\": resume.get(\"id\"),\n",
    "        \"predicted_label\": pred_label,\n",
    "        \"predicted_confidence\": pred_conf,\n",
    "        \"rule_based_explanation\": rule_text,\n",
    "        \"matched_skills\": resume.get(\"matched_skills\", matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])[0]),\n",
    "        \"missing_skills\": resume.get(\"missing_skills\", matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])[1]),\n",
    "        \"feature_summary\": {\n",
    "            \"skill_match_ratio\": matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])[2],\n",
    "            \"years_experience\": sum([e.get(\"years\",0) for e in resume.get(\"work_experience\",[])]),\n",
    "            \"project_count\": len(resume.get(\"projects\",[])),\n",
    "            \"test_score\": resume.get(\"test_score\")\n",
    "        },\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"borderline_flag\": borderline_flag,\n",
    "        \"shap_top_contributions\": shap_result\n",
    "    }\n",
    "    return explanation\n",
    "\n",
    "# ================================\n",
    "# Example usage\n",
    "# ================================\n",
    "\n",
    "# Choose a sample resume from the cleaned/balanced dataset\n",
    "sample_resume = balanced_resumes[0]   # or final_resumes[0], etc.\n",
    "\n",
    "# Provide a small background list for SHAP (optional)\n",
    "background = balanced_resumes[1:101] if len(balanced_resumes) > 101 else balanced_resumes[:50]\n",
    "\n",
    "# Generate explanation (without SHAP)\n",
    "explanation = explain_resume(sample_resume, skill_index, project_scaler, years_scaler, background_resumes_for_shap=background, use_shap=False)\n",
    "print(\"\\n--- Rule-based explanation (short) ---\\n\")\n",
    "print(\"\\n\".join(textwrap.wrap(explanation[\"rule_based_explanation\"], width=120)))\n",
    "\n",
    "# If you have shap installed and want SHAP attribution (slower), set use_shap=True\n",
    "# explanation_shap = explain_resume(sample_resume, skill_index, project_scaler, years_scaler, background_resumes_for_shap=background, shap_nsamples=100, use_shap=True)\n",
    "# print(\"SHAP contributions:\", explanation_shap[\"shap_top_contributions\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a3ec82-d3b4-42ff-886d-851368d77e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final JSON Output ===\n",
      "{\n",
      "  \"id\": \"candidate_0000\",\n",
      "  \"label\": \"Not Fit\",\n",
      "  \"confidence\": 0.606,\n",
      "  \"matched_skills\": [\n",
      "    \"CI/CD\"\n",
      "  ],\n",
      "  \"missing_skills\": [\n",
      "    \"AWS\",\n",
      "    \"Kubernetes\",\n",
      "    \"Terraform\",\n",
      "    \"Azure\",\n",
      "    \"Linux\",\n",
      "    \"Docker\"\n",
      "  ],\n",
      "  \"feature_summary\": {\n",
      "    \"skill_match_ratio\": 0.0,\n",
      "    \"years_experience\": 5.0,\n",
      "    \"test_score\": 0.54,\n",
      "    \"project_count\": 2\n",
      "  },\n",
      "  \"explanation\": \"Predicted label: Not Fit (model confidence: 0.61)\\nRaw test score: 54 / 100 (normalized: 0.54)\\nSkill match: 0 / 7 \\u2192 ratio 0.00\\nProjects: 2; Years experience (sum): 5.0\\nTop missing required skills: AWS, Kubernetes, Terraform\\nRecommendations: Add containerization (Docker) example or CI/CD step.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 9 â€” Postprocessing: Final JSON Output\n",
    "# ================================\n",
    "\n",
    "def build_final_output(resume, skill_index, project_scaler, years_scaler, label_encoder, use_shap=False):\n",
    "    # Run explanation function (which also predicts)\n",
    "    explanation = explain_resume(\n",
    "        resume,\n",
    "        skill_index,\n",
    "        project_scaler,\n",
    "        years_scaler,\n",
    "        background_resumes_for_shap=None,\n",
    "        use_shap=use_shap\n",
    "    )\n",
    "    \n",
    "    # Format final JSON\n",
    "    output_json = {\n",
    "        \"id\": resume.get(\"id\"),\n",
    "        \"label\": explanation[\"predicted_label\"],\n",
    "        \"confidence\": round(explanation[\"predicted_confidence\"], 3),\n",
    "        \"matched_skills\": explanation[\"matched_skills\"],\n",
    "        \"missing_skills\": explanation[\"missing_skills\"],\n",
    "        \"feature_summary\": {\n",
    "            \"skill_match_ratio\": round(explanation[\"feature_summary\"][\"skill_match_ratio\"], 2),\n",
    "            \"years_experience\": explanation[\"feature_summary\"][\"years_experience\"],\n",
    "            \"test_score\": round(explanation[\"feature_summary\"][\"test_score\"] / 100, 2),  # normalized\n",
    "            \"project_count\": explanation[\"feature_summary\"][\"project_count\"]\n",
    "        },\n",
    "        \"explanation\": explanation[\"rule_based_explanation\"]\n",
    "    }\n",
    "    \n",
    "    return output_json\n",
    "\n",
    "\n",
    "# Example usage with one candidate\n",
    "sample_resume = balanced_resumes[0]\n",
    "final_json = build_final_output(sample_resume, skill_index, project_scaler, years_scaler, label_encoder, use_shap=False)\n",
    "\n",
    "import json\n",
    "print(\"=== Final JSON Output ===\")\n",
    "print(json.dumps(final_json, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4324bc73-a4df-4ea5-a829-766f98cf58b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model & artifacts saved in 'models/' directory\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 10 â€” Save Model & Artifacts\n",
    "# ================================\n",
    "import joblib\n",
    "\n",
    "# Save model (TensorFlow SavedModel format)\n",
    "# Save final model in .keras format\n",
    "model.save(\"models/resume_classifier.keras\")\n",
    "\n",
    "\n",
    "# Save scalers\n",
    "joblib.dump(project_scaler, \"models/project_scaler.pkl\")\n",
    "joblib.dump(years_scaler, \"models/years_scaler.pkl\")\n",
    "\n",
    "# Save skill vocabulary\n",
    "with open(\"models/skill_vocab.json\", \"w\") as f:\n",
    "    json.dump(skill_vocab, f, indent=2)\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(label_encoder, \"models/label_encoder.pkl\")\n",
    "\n",
    "# Optional: save explanation templates or SHAP background set\n",
    "# Optional: save explanation templates or SHAP background set\n",
    "with open(\"models/explanation_template.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\n",
    "        \"Template: High test score ({score}) and covers {matched}/{total} required skills. \"\n",
    "        \"Missing {missing}. Projects: {projects}; Experience: {experience} years. \"\n",
    "        \"Confidence: {confidence:.2f} â†’ {label}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"âœ… Model & artifacts saved in 'models/' directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547fac7-6d09-42e6-b204-4a85faa1f083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "691b291d-3bb2-437d-85fb-f5814dad58a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and artifacts...\n",
      "âœ… Artifacts loaded.\n",
      "âœ… Predictions completed for 5 resumes and saved to data/predictions.json\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 11 â€” Test New Resumes\n",
    "# ================================\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load saved artifacts\n",
    "# -------------------------------\n",
    "print(\"Loading model and artifacts...\")\n",
    "model = keras.models.load_model(\"models/resume_classifier.keras\")\n",
    "project_scaler = joblib.load(\"models/project_scaler.pkl\")\n",
    "years_scaler = joblib.load(\"models/years_scaler.pkl\")\n",
    "with open(\"models/skill_vocab.json\", \"r\") as f:\n",
    "    skill_vocab = json.load(f)\n",
    "skill_index = {s: i for i, s in enumerate(skill_vocab)}\n",
    "label_encoder = joblib.load(\"models/label_encoder.pkl\")\n",
    "\n",
    "print(\"âœ… Artifacts loaded.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Helper functions (from Step 3 & 4)\n",
    "# -------------------------------\n",
    "\n",
    "def encode_skills(candidate_skills, skill_index):\n",
    "    vector = np.zeros(len(skill_index), dtype=int)\n",
    "    for s in candidate_skills:\n",
    "        if s in skill_index:\n",
    "            vector[skill_index[s]] = 1\n",
    "    return vector\n",
    "\n",
    "def matched_missing_skills(candidate_skills, domain_required_skills):\n",
    "    candidate_set = set(candidate_skills)\n",
    "    required_set = set(domain_required_skills)\n",
    "    matched = list(candidate_set.intersection(required_set))\n",
    "    missing = list(required_set - candidate_set)\n",
    "    ratio = len(matched) / len(required_set) if required_set else 0\n",
    "    return matched, missing, round(ratio, 2)\n",
    "\n",
    "def extract_project_experience_features(resume):\n",
    "    project_count = len(resume.get(\"projects\", []))\n",
    "    years_experience = sum(item.get(\"years\", 0) for item in resume.get(\"work_experience\", []))\n",
    "    return project_count, years_experience\n",
    "\n",
    "def normalize_test_score(score):\n",
    "    return round(score / 100, 2)\n",
    "\n",
    "def transform_numeric_features(resume, project_scaler, years_scaler):\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    project_scaled = project_scaler.transform([[project_count]])[0][0]\n",
    "    years_scaled = years_scaler.transform([[years_exp]])[0][0]\n",
    "    return project_scaled, years_scaled\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Build final vector & predict\n",
    "# -------------------------------\n",
    "\n",
    "def build_flat_vector(resume, skill_index, project_scaler, years_scaler, domain_requirements):\n",
    "    skill_vec = encode_skills(resume[\"skills\"], skill_index)\n",
    "    domain = resume[\"preferred_domain\"]\n",
    "    _, _, ratio = matched_missing_skills(resume[\"skills\"], domain_requirements[domain][\"required_skills\"])\n",
    "    skill_features = np.append(skill_vec, ratio).astype(float)\n",
    "\n",
    "    project_scaled, years_scaled = transform_numeric_features(resume, project_scaler, years_scaler)\n",
    "    test_score_norm = normalize_test_score(resume.get(\"test_score\", 0))\n",
    "    numeric_vector = np.array([test_score_norm, project_scaled, years_scaled, ratio], dtype=float)\n",
    "\n",
    "    flat_vector = np.concatenate([skill_features, numeric_vector])\n",
    "    return flat_vector\n",
    "\n",
    "def predict_resume(resume, domain_requirements):\n",
    "    flat = build_flat_vector(resume, skill_index, project_scaler, years_scaler, domain_requirements)\n",
    "    V_plus_ratio = len(skill_vocab) + 1\n",
    "    skill_input = flat[:V_plus_ratio].reshape(1, -1)\n",
    "    numeric_input = flat[V_plus_ratio:V_plus_ratio + 4].reshape(1, -1)\n",
    "    probs = model.predict({\"skill_input\": skill_input, \"numeric_input\": numeric_input}, verbose=0)\n",
    "    pred_idx = int(np.argmax(probs))\n",
    "    pred_label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "    confidence = float(np.max(probs))\n",
    "    matched, missing, _ = matched_missing_skills(resume[\"skills\"], domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"])\n",
    "    project_count, years_exp = extract_project_experience_features(resume)\n",
    "    return {\n",
    "        \"id\": resume.get(\"id\"),\n",
    "        \"label\": pred_label,\n",
    "        \"confidence\": round(confidence, 3),\n",
    "        \"matched_skills\": matched,\n",
    "        \"missing_skills\": missing,\n",
    "        \"feature_summary\": {\n",
    "            \"skill_match_ratio\": round(len(matched) / len(domain_requirements[resume[\"preferred_domain\"]][\"required_skills\"]), 2),\n",
    "            \"years_experience\": years_exp,\n",
    "            \"test_score\": round(normalize_test_score(resume.get(\"test_score\", 0)), 2),\n",
    "            \"project_count\": project_count\n",
    "        }\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Load new resumes dataset\n",
    "# -------------------------------\n",
    "with open(\"data/new_resumes.json\", \"r\") as f:\n",
    "    new_resumes = json.load(f)\n",
    "\n",
    "# Replace this with your actual domain requirements\n",
    "with open(\"data/domain_requirements/data_science.json\") as f:\n",
    "    data_science_req = json.load(f)\n",
    "with open(\"data/domain_requirements/web_development.json\") as f:\n",
    "    web_req = json.load(f)\n",
    "with open(\"data/domain_requirements/cloud_engineering.json\") as f:\n",
    "    cloud_req = json.load(f)\n",
    "domain_requirements = {\n",
    "    \"Data Science\": data_science_req,\n",
    "    \"Web Development\": web_req,\n",
    "    \"Cloud Engineering\": cloud_req\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Predict & save\n",
    "# -------------------------------\n",
    "results = []\n",
    "for resume in new_resumes:\n",
    "    output = predict_resume(resume, domain_requirements)\n",
    "    results.append(output)\n",
    "\n",
    "with open(\"data/predictions.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Predictions completed for {len(results)} resumes and saved to data/predictions.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ad5aaee-9175-4279-bc78-44806c596a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and artifacts...\n",
      "âœ… Artifacts loaded.\n",
      "âœ… Predictions with explanations completed for 5 resumes and saved to data/predictions.json\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 11 â€” Test New Resumes (with explanations)\n",
    "# ================================\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load saved artifacts\n",
    "# -------------------------------\n",
    "print(\"Loading model and artifacts...\")\n",
    "model = keras.models.load_model(\"models/resume_classifier.keras\")\n",
    "project_scaler = joblib.load(\"models/project_scaler.pkl\")\n",
    "years_scaler = joblib.load(\"models/years_scaler.pkl\")\n",
    "with open(\"models/skill_vocab.json\", \"r\") as f:\n",
    "    skill_vocab = json.load(f)\n",
    "skill_index = {s: i for i, s in enumerate(skill_vocab)}\n",
    "label_encoder = joblib.load(\"models/label_encoder.pkl\")\n",
    "print(\"âœ… Artifacts loaded.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load new resumes dataset\n",
    "# -------------------------------\n",
    "with open(\"data/new_resumes.json\", \"r\") as f:\n",
    "    new_resumes = json.load(f)\n",
    "\n",
    "# Load domain requirements\n",
    "with open(\"data/domain_requirements/data_science.json\") as f:\n",
    "    data_science_req = json.load(f)\n",
    "with open(\"data/domain_requirements/web_development.json\") as f:\n",
    "    web_req = json.load(f)\n",
    "with open(\"data/domain_requirements/cloud_engineering.json\") as f:\n",
    "    cloud_req = json.load(f)\n",
    "\n",
    "domain_requirements = {\n",
    "    \"Data Science\": data_science_req,\n",
    "    \"Web Development\": web_req,\n",
    "    \"Cloud Engineering\": cloud_req\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Predict & build final JSON output\n",
    "# -------------------------------\n",
    "results = []\n",
    "for resume in new_resumes:\n",
    "    output_json = build_final_output(\n",
    "        resume,\n",
    "        skill_index,\n",
    "        project_scaler,\n",
    "        years_scaler,\n",
    "        label_encoder,\n",
    "        use_shap=False  # set True if SHAP is installed and desired\n",
    "    )\n",
    "    results.append(output_json)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Save predictions\n",
    "# -------------------------------\n",
    "with open(\"data/predictions.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Predictions with explanations completed for {len(results)} resumes and saved to data/predictions.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708493e-f164-49c8-ae67-85183efa7243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
